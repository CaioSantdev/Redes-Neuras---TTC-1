{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc003b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Acurácia e Métricas por Coluna ===\n",
      "\n",
      "Acurácia para 'Interaction in patenting process. Active or passive?': 88.89%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Active       0.78      0.88      0.82         8\n",
      "     Passive       0.94      0.89      0.92        19\n",
      "\n",
      "    accuracy                           0.89        27\n",
      "   macro avg       0.86      0.88      0.87        27\n",
      "weighted avg       0.90      0.89      0.89        27\n",
      "\n",
      "\n",
      "Acurácia para 'Classification regarding professional orientation': 51.85%\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "      Entrepreneurial       0.45      0.50      0.48        10\n",
      "               Hybrid       0.56      0.69      0.62        13\n",
      "Pragmatic traditional       0.00      0.00      0.00         4\n",
      "\n",
      "             accuracy                           0.52        27\n",
      "            macro avg       0.34      0.40      0.37        27\n",
      "         weighted avg       0.44      0.52      0.48        27\n",
      "\n",
      "\n",
      "Acurácia para 'Nature of motivation': 40.74%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Extrinsic       0.38      0.56      0.45         9\n",
      "   Intrinsic       0.43      0.30      0.35        10\n",
      "       Mixed       0.43      0.38      0.40         8\n",
      "\n",
      "    accuracy                           0.41        27\n",
      "   macro avg       0.41      0.41      0.40        27\n",
      "weighted avg       0.41      0.41      0.40        27\n",
      "\n",
      "\n",
      "Acurácia para 'Relationship between standards / personal values': 48.15%\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "identification       0.50      0.38      0.43        13\n",
      "   integration       0.50      0.67      0.57         6\n",
      "  introjection       0.44      0.50      0.47         8\n",
      "\n",
      "      accuracy                           0.48        27\n",
      "     macro avg       0.48      0.52      0.49        27\n",
      "  weighted avg       0.48      0.48      0.48        27\n",
      "\n",
      "\n",
      "=== Acurácia média geral: 57.41% ===\n",
      "\n",
      "=== Acurácia com Validação Cruzada ===\n",
      "Fold 1: 57.39%\n",
      "Fold 2: 57.39%\n",
      "Fold 3: 56.40%\n",
      "Acurácia média (cross-val): 57.06%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Carregar dados\n",
    "file_path = './dados_funcionais_patenteadores.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Colunas alvo (múltiplas saídas)\n",
    "target_columns = [\n",
    "    \"Interaction in patenting process. Active or passive?\",\n",
    "    \"Classification regarding professional orientation\",\n",
    "    \"Nature of motivation\",\n",
    "    \"Relationship between standards / personal values\"\n",
    "]\n",
    "\n",
    "X = df.drop(columns=target_columns)\n",
    "y = df[target_columns]\n",
    "\n",
    "# Identificar colunas numéricas e categóricas\n",
    "numeric_features = X.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Pré-processamento\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), numeric_features),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "])\n",
    "\n",
    "# Modelo base\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(128, 64, 32), max_iter=2000, random_state=42, solver='adam', activation='relu')\n",
    "multi_output_mlp = MultiOutputClassifier(mlp)\n",
    "\n",
    "# Pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', multi_output_mlp)\n",
    "])\n",
    "\n",
    "# Dividir os dados\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Treinar o modelo\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Prever\n",
    "y_pred = pipeline.predict(X_test)\n",
    "y_pred_df = pd.DataFrame(y_pred, columns=target_columns, index=y_test.index)\n",
    "\n",
    "# Avaliação por coluna com classification_report\n",
    "print(\"=== Acurácia e Métricas por Coluna ===\")\n",
    "accuracies = []\n",
    "for col in target_columns:\n",
    "    acc = accuracy_score(y_test[col], y_pred_df[col])\n",
    "    accuracies.append(acc)\n",
    "    print(f\"\\nAcurácia para '{col}': {acc:.2%}\")\n",
    "    print(classification_report(y_test[col], y_pred_df[col], zero_division=0))\n",
    "\n",
    "# Acurácia média geral\n",
    "mean_accuracy = np.mean(accuracies)\n",
    "print(f\"\\n=== Acurácia média geral: {mean_accuracy:.2%} ===\")\n",
    "\n",
    "# Validação cruzada manual\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "cv_scores = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_cv_train, X_cv_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_cv_train, y_cv_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    pipeline.fit(X_cv_train, y_cv_train)\n",
    "    y_cv_pred = pipeline.predict(X_cv_test)\n",
    "    \n",
    "    accs = []\n",
    "    for i, col in enumerate(y.columns):\n",
    "        acc = accuracy_score(y_cv_test[col], y_cv_pred[:, i])\n",
    "        accs.append(acc)\n",
    "    \n",
    "    cv_scores.append(np.mean(accs))\n",
    "\n",
    "print(\"\\n=== Acurácia com Validação Cruzada ===\")\n",
    "for i, score in enumerate(cv_scores, 1):\n",
    "    print(f\"Fold {i}: {score:.2%}\")\n",
    "print(f\"Acurácia média (cross-val): {np.mean(cv_scores):.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18301f8-3dd7-4336-9938-f8b024a198ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.6296296296296297\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Carregar os dados (substitua 'SuaÚltimaColuna' pelo nome real da última coluna)\n",
    "file_path = './dados_funcionais_patenteadores.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "\n",
    "# target_column = 'Interaction in patenting process. Active or passive?'  \n",
    "target_column = 'Classification regarding professional orientation' \n",
    "# target_column = 'Nature of motivation' \n",
    "# target_column = 'Relationship between standards / personal values' \n",
    "X = df.drop(columns=[target_column])\n",
    "y = df[target_column]\n",
    "\n",
    "# Pré-processamento: normalização de variáveis numéricas e codificação de variáveis categóricas\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), X.select_dtypes(include=['float64', 'int64']).columns),  # Normaliza dados numéricos\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), X.select_dtypes(include=['object']).columns)  # Codifica dados categóricos\n",
    "    ])\n",
    "\n",
    "# Divisão dos dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Criar o pipeline que aplica o pré-processamento e o modelo MLP\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('mlp', MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "# Treinar o modelo\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Avaliar a acurácia do modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Acurácia: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff47bda2-0312-4441-b621-c20f78fb3976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.5185185185185185\n",
      "Acurácia média com validação cruzada: 0.5343551797040168\n",
      "\n",
      "Resultados das Previsões (Classes Reais vs Previsões):\n",
      "          Real   Previsto\n",
      "55   Intrinsic  Intrinsic\n",
      "40       Mixed  Extrinsic\n",
      "19   Extrinsic  Intrinsic\n",
      "31       Mixed      Mixed\n",
      "115  Intrinsic  Extrinsic\n",
      "56   Extrinsic  Extrinsic\n",
      "69       Mixed      Mixed\n",
      "105  Extrinsic  Intrinsic\n",
      "81   Intrinsic  Extrinsic\n",
      "26   Extrinsic      Mixed\n",
      "95   Intrinsic  Intrinsic\n",
      "27   Intrinsic  Intrinsic\n",
      "64       Mixed  Extrinsic\n",
      "4    Intrinsic  Extrinsic\n",
      "97   Intrinsic      Mixed\n",
      "100      Mixed      Mixed\n",
      "36   Intrinsic      Mixed\n",
      "80   Extrinsic  Intrinsic\n",
      "93       Mixed  Extrinsic\n",
      "84   Extrinsic  Extrinsic\n",
      "18   Extrinsic  Extrinsic\n",
      "10       Mixed      Mixed\n",
      "122  Extrinsic  Extrinsic\n",
      "11   Extrinsic  Extrinsic\n",
      "127      Mixed      Mixed\n",
      "45   Intrinsic  Intrinsic\n",
      "70   Intrinsic  Extrinsic\n",
      "\n",
      "Número de acertos por classe:\n",
      "Real\n",
      "Extrinsic    5\n",
      "Intrinsic    4\n",
      "Mixed        5\n",
      "dtype: int64\n",
      "\n",
      "Previsões Erradas (Real vs Previsto):\n",
      "          Real   Previsto\n",
      "40       Mixed  Extrinsic\n",
      "19   Extrinsic  Intrinsic\n",
      "115  Intrinsic  Extrinsic\n",
      "105  Extrinsic  Intrinsic\n",
      "81   Intrinsic  Extrinsic\n",
      "26   Extrinsic      Mixed\n",
      "64       Mixed  Extrinsic\n",
      "4    Intrinsic  Extrinsic\n",
      "97   Intrinsic      Mixed\n",
      "36   Intrinsic      Mixed\n",
      "80   Extrinsic  Intrinsic\n",
      "93       Mixed  Extrinsic\n",
      "70   Intrinsic  Extrinsic\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "file_path = './dados_funcionais_patenteadores.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# target_column = 'Classification regarding professional orientation' \n",
    "target_column = 'Nature of motivation'\n",
    "# target_column = 'Relationship between standards / personal values' \n",
    "X = df.drop(columns=[target_column])\n",
    "y = df[target_column]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), X.select_dtypes(include=['float64', 'int64']).columns),  # Normaliza dados numéricos\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), X.select_dtypes(include=['object']).columns)  # Codifica dados categóricos\n",
    "    ])\n",
    "\n",
    "#dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('mlp', MLPClassifier(hidden_layer_sizes=(128, 64, 32), max_iter=2000, random_state=42, solver='adam', activation='relu'))\n",
    "])\n",
    "\n",
    "# treino\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# previsoes nos testes\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Acurácia: {accuracy}')\n",
    "\n",
    "\n",
    "cv_scores = cross_val_score(pipeline, X, y, cv=3, scoring='accuracy')\n",
    "print(f\"Acurácia média com validação cruzada: {cv_scores.mean()}\")\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Real': y_test,\n",
    "    'Previsto': y_pred\n",
    "})\n",
    "\n",
    "print(\"\\nResultados das Previsões (Classes Reais vs Previsões):\")\n",
    "print(results_df.head(50)) \n",
    "\n",
    "print(\"\\nNúmero de acertos por classe:\")\n",
    "print(results_df[results_df['Real'] == results_df['Previsto']].groupby('Real').size())\n",
    "\n",
    "print(\"\\nPrevisões Erradas (Real vs Previsto):\")\n",
    "print(results_df[results_df['Real'] != results_df['Previsto']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2489530e-da1a-4027-bd8c-d1775a7ace0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-05 14:55:48.589770: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-05 14:55:48.709346: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-05 14:55:48.773212: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746467748.837874 3310317 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746467748.857384 3310317 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746467748.987841 3310317 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746467748.987892 3310317 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746467748.987894 3310317 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746467748.987896 3310317 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-05 14:55:49.004254: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-05 14:55:51.577208: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.2673 - val_loss: 0.2585\n",
      "Epoch 2/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2630 - val_loss: 0.2505\n",
      "Epoch 3/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.2532 - val_loss: 0.2306\n",
      "Epoch 4/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.2294 - val_loss: 0.1865\n",
      "Epoch 5/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1792 - val_loss: 0.1141\n",
      "Epoch 6/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.1063 - val_loss: 0.0583\n",
      "Epoch 7/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0613 - val_loss: 0.0472\n",
      "Epoch 8/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0537 - val_loss: 0.0465\n",
      "Epoch 9/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0529 - val_loss: 0.0459\n",
      "Epoch 10/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0522 - val_loss: 0.0445\n",
      "Epoch 11/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0514 - val_loss: 0.0438\n",
      "Epoch 12/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0511 - val_loss: 0.0438\n",
      "Epoch 13/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0509 - val_loss: 0.0437\n",
      "Epoch 14/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0508 - val_loss: 0.0433\n",
      "Epoch 15/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0505 - val_loss: 0.0432\n",
      "Epoch 16/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0504 - val_loss: 0.0432\n",
      "Epoch 17/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0503 - val_loss: 0.0432\n",
      "Epoch 18/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0502 - val_loss: 0.0430\n",
      "Epoch 19/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0500 - val_loss: 0.0428\n",
      "Epoch 20/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0498 - val_loss: 0.0427\n",
      "Epoch 21/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0496 - val_loss: 0.0426\n",
      "Epoch 22/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0493 - val_loss: 0.0424\n",
      "Epoch 23/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0490 - val_loss: 0.0421\n",
      "Epoch 24/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0486 - val_loss: 0.0418\n",
      "Epoch 25/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0482 - val_loss: 0.0415\n",
      "Epoch 26/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0478 - val_loss: 0.0412\n",
      "Epoch 27/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0474 - val_loss: 0.0408\n",
      "Epoch 28/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0470 - val_loss: 0.0406\n",
      "Epoch 29/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0467 - val_loss: 0.0404\n",
      "Epoch 30/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0464 - val_loss: 0.0402\n",
      "Epoch 31/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0461 - val_loss: 0.0400\n",
      "Epoch 32/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0459 - val_loss: 0.0399\n",
      "Epoch 33/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0456 - val_loss: 0.0397\n",
      "Epoch 34/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0453 - val_loss: 0.0395\n",
      "Epoch 35/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0450 - val_loss: 0.0393\n",
      "Epoch 36/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0447 - val_loss: 0.0391\n",
      "Epoch 37/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0444 - val_loss: 0.0389\n",
      "Epoch 38/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0442 - val_loss: 0.0387\n",
      "Epoch 39/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0439 - val_loss: 0.0385\n",
      "Epoch 40/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0437 - val_loss: 0.0384\n",
      "Epoch 41/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0434 - val_loss: 0.0382\n",
      "Epoch 42/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0432 - val_loss: 0.0380\n",
      "Epoch 43/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0430 - val_loss: 0.0378\n",
      "Epoch 44/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0428 - val_loss: 0.0376\n",
      "Epoch 45/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0427 - val_loss: 0.0375\n",
      "Epoch 46/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0425 - val_loss: 0.0374\n",
      "Epoch 47/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0423 - val_loss: 0.0373\n",
      "Epoch 48/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0422 - val_loss: 0.0372\n",
      "Epoch 49/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0421 - val_loss: 0.0371\n",
      "Epoch 50/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0419 - val_loss: 0.0370\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/caio/Área de trabalho/tcc/venv/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.3141 - loss: 1.2979 - val_accuracy: 0.2222 - val_loss: 1.1622\n",
      "Epoch 2/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4063 - loss: 1.0965 - val_accuracy: 0.2963 - val_loss: 1.1552\n",
      "Epoch 3/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4391 - loss: 1.0413 - val_accuracy: 0.3704 - val_loss: 1.0977\n",
      "Epoch 4/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4635 - loss: 1.0238 - val_accuracy: 0.4815 - val_loss: 1.0718\n",
      "Epoch 5/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5115 - loss: 1.0182 - val_accuracy: 0.5926 - val_loss: 1.0630\n",
      "Epoch 6/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5352 - loss: 0.9860 - val_accuracy: 0.5556 - val_loss: 1.0541\n",
      "Epoch 7/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5352 - loss: 0.9664 - val_accuracy: 0.5556 - val_loss: 1.0299\n",
      "Epoch 8/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5470 - loss: 0.9548 - val_accuracy: 0.5556 - val_loss: 1.0220\n",
      "Epoch 9/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5840 - loss: 0.9475 - val_accuracy: 0.5556 - val_loss: 1.0116\n",
      "Epoch 10/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5871 - loss: 0.9380 - val_accuracy: 0.4815 - val_loss: 1.0114\n",
      "Epoch 11/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5909 - loss: 0.9281 - val_accuracy: 0.4815 - val_loss: 1.0127\n",
      "Epoch 12/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5878 - loss: 0.9239 - val_accuracy: 0.4815 - val_loss: 1.0020\n",
      "Epoch 13/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6184 - loss: 0.9221 - val_accuracy: 0.4815 - val_loss: 0.9950\n",
      "Epoch 14/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6212 - loss: 0.9096 - val_accuracy: 0.5185 - val_loss: 0.9929\n",
      "Epoch 15/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6275 - loss: 0.8994 - val_accuracy: 0.4815 - val_loss: 0.9894\n",
      "Epoch 16/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6122 - loss: 0.9017 - val_accuracy: 0.5556 - val_loss: 0.9900\n",
      "Epoch 17/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6365 - loss: 0.8873 - val_accuracy: 0.4815 - val_loss: 0.9722\n",
      "Epoch 18/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6637 - loss: 0.8823 - val_accuracy: 0.4815 - val_loss: 0.9733\n",
      "Epoch 19/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6637 - loss: 0.8723 - val_accuracy: 0.4815 - val_loss: 0.9735\n",
      "Epoch 20/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6700 - loss: 0.8661 - val_accuracy: 0.5556 - val_loss: 0.9753\n",
      "Epoch 21/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6640 - loss: 0.8539 - val_accuracy: 0.4815 - val_loss: 0.9737\n",
      "Epoch 22/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6578 - loss: 0.8471 - val_accuracy: 0.4815 - val_loss: 0.9655\n",
      "Epoch 23/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6700 - loss: 0.8429 - val_accuracy: 0.5185 - val_loss: 0.9779\n",
      "Epoch 24/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6609 - loss: 0.8286 - val_accuracy: 0.4815 - val_loss: 0.9705\n",
      "Epoch 25/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6700 - loss: 0.8262 - val_accuracy: 0.5185 - val_loss: 0.9688\n",
      "Epoch 26/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6609 - loss: 0.8154 - val_accuracy: 0.5185 - val_loss: 0.9653\n",
      "Epoch 27/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6700 - loss: 0.8074 - val_accuracy: 0.5185 - val_loss: 0.9676\n",
      "Epoch 28/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6700 - loss: 0.8012 - val_accuracy: 0.5185 - val_loss: 0.9680\n",
      "Epoch 29/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6700 - loss: 0.7929 - val_accuracy: 0.5185 - val_loss: 0.9676\n",
      "Epoch 30/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6762 - loss: 0.7832 - val_accuracy: 0.5185 - val_loss: 0.9669\n",
      "Epoch 31/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6793 - loss: 0.7747 - val_accuracy: 0.5185 - val_loss: 0.9591\n",
      "Epoch 32/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6974 - loss: 0.7678 - val_accuracy: 0.5185 - val_loss: 0.9625\n",
      "Epoch 33/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7065 - loss: 0.7590 - val_accuracy: 0.5185 - val_loss: 0.9663\n",
      "Epoch 34/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7034 - loss: 0.7524 - val_accuracy: 0.5185 - val_loss: 0.9752\n",
      "Epoch 35/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7124 - loss: 0.7421 - val_accuracy: 0.4815 - val_loss: 0.9641\n",
      "Epoch 36/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6974 - loss: 0.7366 - val_accuracy: 0.4815 - val_loss: 0.9676\n",
      "Epoch 37/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7124 - loss: 0.7271 - val_accuracy: 0.4815 - val_loss: 0.9730\n",
      "Epoch 38/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7183 - loss: 0.7203 - val_accuracy: 0.4815 - val_loss: 0.9751\n",
      "Epoch 39/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7430 - loss: 0.7103 - val_accuracy: 0.5185 - val_loss: 0.9711\n",
      "Epoch 40/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7490 - loss: 0.7034 - val_accuracy: 0.5185 - val_loss: 0.9792\n",
      "Epoch 41/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7490 - loss: 0.6934 - val_accuracy: 0.5185 - val_loss: 0.9777\n",
      "Epoch 42/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7490 - loss: 0.6861 - val_accuracy: 0.5185 - val_loss: 0.9756\n",
      "Epoch 43/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7490 - loss: 0.6790 - val_accuracy: 0.5185 - val_loss: 0.9879\n",
      "Epoch 44/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7490 - loss: 0.6663 - val_accuracy: 0.5185 - val_loss: 0.9882\n",
      "Epoch 45/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7608 - loss: 0.6643 - val_accuracy: 0.5185 - val_loss: 0.9953\n",
      "Epoch 46/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7549 - loss: 0.6525 - val_accuracy: 0.5185 - val_loss: 0.9976\n",
      "Epoch 47/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7608 - loss: 0.6437 - val_accuracy: 0.5185 - val_loss: 0.9912\n",
      "Epoch 48/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7608 - loss: 0.6375 - val_accuracy: 0.5185 - val_loss: 1.0040\n",
      "Epoch 49/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7789 - loss: 0.6272 - val_accuracy: 0.5185 - val_loss: 1.0014\n",
      "Epoch 50/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7608 - loss: 0.6212 - val_accuracy: 0.5185 - val_loss: 1.0135\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Acurácia do modelo com Autoencoder + MLP: 0.5185185185185185\n",
      "\n",
      "Resultados das Previsões (Classes Reais vs Previsões):\n",
      "        Real   Previsto\n",
      "0  Intrinsic  Intrinsic\n",
      "1      Mixed      Mixed\n",
      "2  Extrinsic  Intrinsic\n",
      "3      Mixed  Extrinsic\n",
      "4  Intrinsic      Mixed\n",
      "5  Extrinsic  Intrinsic\n",
      "6      Mixed      Mixed\n",
      "7  Extrinsic  Intrinsic\n",
      "8  Intrinsic  Extrinsic\n",
      "9  Extrinsic  Intrinsic\n",
      "\n",
      "Número de acertos por classe:\n",
      "Real\n",
      "Extrinsic    5\n",
      "Intrinsic    4\n",
      "Mixed        5\n",
      "dtype: int64\n",
      "\n",
      "Previsões Erradas (Real vs Previsto):\n",
      "         Real   Previsto\n",
      "2   Extrinsic  Intrinsic\n",
      "3       Mixed  Extrinsic\n",
      "4   Intrinsic      Mixed\n",
      "5   Extrinsic  Intrinsic\n",
      "7   Extrinsic  Intrinsic\n",
      "8   Intrinsic  Extrinsic\n",
      "9   Extrinsic  Intrinsic\n",
      "12      Mixed  Intrinsic\n",
      "13  Intrinsic  Extrinsic\n",
      "14  Intrinsic      Mixed\n",
      "16  Intrinsic  Extrinsic\n",
      "21      Mixed  Intrinsic\n",
      "26  Intrinsic  Extrinsic\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Definir a semente para garantir reprodutibilidade\n",
    "seed_value = 42\n",
    "\n",
    "# Definir semente do Python\n",
    "random.seed(seed_value)\n",
    "\n",
    "# Definir semente do NumPy\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# Definir semente do TensorFlow\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "# Importações do código original\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Carregar os dados\n",
    "df = pd.read_excel('./dados_funcionais_patenteadores.xlsx')\n",
    "\n",
    "# Selecione a coluna alvo e as variáveis de entrada\n",
    "X = df.drop(columns=['Nature of motivation'])\n",
    "y = df['Nature of motivation']\n",
    "\n",
    "# Selecionar apenas as colunas numéricas para normalização\n",
    "X_numeric = X.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Normalização dos dados numéricos\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_numeric)\n",
    "\n",
    "# Selecionar as colunas categóricas para codificação\n",
    "X_categorical = X.select_dtypes(include=['object'])\n",
    "\n",
    "# Codificação das variáveis categóricas com OneHotEncoder\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False) \n",
    "X_encoded = encoder.fit_transform(X_categorical)\n",
    "\n",
    "# Concatenar as variáveis numéricas normalizadas com as variáveis categóricas codificadas\n",
    "X_final = np.concatenate((X_scaled, X_encoded), axis=1)\n",
    "\n",
    "# Convertendo as variáveis alvo (y_train e y_test) para inteiros\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Dividir os dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- Construção do Autoencoder ---\n",
    "input_dim = X_train.shape[1]  # Número total de características de entrada\n",
    "encoding_dim = 64  # Dimensão da camada comprimida (representação compacta)\n",
    "\n",
    "# Definir o Autoencoder\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoded = Dense(128, activation='relu')(input_layer)\n",
    "encoded = Dense(64, activation='relu')(encoded)\n",
    "encoded = Dense(encoding_dim, activation='relu')(encoded)\n",
    "\n",
    "decoded = Dense(64, activation='relu')(encoded)\n",
    "decoded = Dense(128, activation='relu')(decoded)\n",
    "decoded = Dense(input_dim, activation='sigmoid')(decoded)\n",
    "\n",
    "# Modelo Autoencoder\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "\n",
    "# Modelo Encoder (para obter a codificação comprimida)\n",
    "encoder_model = Model(input_layer, encoded)\n",
    "\n",
    "# Compilação do Autoencoder\n",
    "autoencoder.compile(optimizer=Adam(), loss='mean_squared_error')\n",
    "\n",
    "# Treinar o Autoencoder\n",
    "autoencoder.fit(X_train, X_train, epochs=50, batch_size=32, validation_data=(X_test, X_test))\n",
    "\n",
    "# --- Obter as Representações Comprimidas com o Encoder ---\n",
    "X_train_encoded = encoder_model.predict(X_train)\n",
    "X_test_encoded = encoder_model.predict(X_test)\n",
    "\n",
    "# --- Construção do MLP ---\n",
    "# O MLP agora vai usar as representações comprimidas como entrada\n",
    "mlp_model = Sequential([\n",
    "    Dense(128, activation='relu', input_dim=encoding_dim),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(len(np.unique(y_encoded)), activation='softmax')  # Para classificação multi-classe\n",
    "])\n",
    "\n",
    "# Compilar o modelo MLP\n",
    "mlp_model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Treinar o MLP\n",
    "mlp_model.fit(X_train_encoded, y_train, epochs=50, batch_size=32, validation_data=(X_test_encoded, y_test))\n",
    "\n",
    "# Avaliar a acurácia do MLP\n",
    "y_pred = mlp_model.predict(X_test_encoded)\n",
    "y_pred_classes = y_pred.argmax(axis=-1)  # Converter as probabilidades para classes\n",
    "\n",
    "# Calcular a acurácia\n",
    "accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "print(f'Acurácia do modelo com Autoencoder + MLP: {accuracy}')\n",
    "\n",
    "\n",
    "# --- Exibir os resultados das previsões ---\n",
    "# Criando uma tabela com as classes reais e previstas\n",
    "results_df = pd.DataFrame({\n",
    "    'Real': label_encoder.inverse_transform(y_test),\n",
    "    'Previsto': label_encoder.inverse_transform(y_pred_classes)\n",
    "})\n",
    "\n",
    "print(\"\\nResultados das Previsões (Classes Reais vs Previsões):\")\n",
    "print(results_df.head(10))  # Exibe as 10 primeiras linhas para ver o resultado\n",
    "\n",
    "# Exibir o número total de acertos para cada classe\n",
    "print(\"\\nNúmero de acertos por classe:\")\n",
    "print(results_df[results_df['Real'] == results_df['Previsto']].groupby('Real').size())\n",
    "\n",
    "# Exibir as previsões erradas\n",
    "print(\"\\nPrevisões Erradas (Real vs Previsto):\")\n",
    "print(results_df[results_df['Real'] != results_df['Previsto']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e20ca24-ed40-455f-aaac-2791ae7a240e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 00:49:47.777358: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-07 00:49:47.959661: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-07 00:49:48.098267: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746589788.224061   17340 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746589788.258141   17340 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746589788.564959   17340 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746589788.564979   17340 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746589788.564982   17340 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746589788.564985   17340 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-07 00:49:48.593913: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/caio/Área de trabalho/Redes-Neuras---TTC-1/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-05-07 00:49:53.056410: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_COMPAT_NOT_SUPPORTED_ON_DEVICE: forward compatibility was attempted on non supported HW\n",
      "2025-05-07 00:49:53.056449: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:178] verbose logging is disabled. Rerun with verbose logging (usually --v=1 or --vmodule=cuda_diagnostics=1) to get more diagnostic output from this module\n",
      "2025-05-07 00:49:53.056454: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:183] retrieving CUDA diagnostic information for host: caio\n",
      "2025-05-07 00:49:53.056458: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:190] hostname: caio\n",
      "2025-05-07 00:49:53.056597: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:197] libcuda reported version is: 550.144.3\n",
      "2025-05-07 00:49:53.056615: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:201] kernel reported version is: 550.120.0\n",
      "2025-05-07 00:49:53.056619: E external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:294] kernel version 550.120.0 does not match DSO version 550.144.3 -- cannot find working devices in this configuration\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.3708 - loss: 1.1021 - val_accuracy: 0.2381 - val_loss: 1.1234\n",
      "Epoch 2/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4380 - loss: 1.0594 - val_accuracy: 0.2381 - val_loss: 1.1262\n",
      "Epoch 3/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5695 - loss: 1.0139 - val_accuracy: 0.2857 - val_loss: 1.1553\n",
      "Epoch 4/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5179 - loss: 0.9603 - val_accuracy: 0.1905 - val_loss: 1.2094\n",
      "Epoch 5/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6378 - loss: 0.8863 - val_accuracy: 0.2857 - val_loss: 1.2059\n",
      "Epoch 6/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6590 - loss: 0.8284 - val_accuracy: 0.2381 - val_loss: 1.3277\n",
      "Epoch 7/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7849 - loss: 0.7144 - val_accuracy: 0.1905 - val_loss: 1.5436\n",
      "Epoch 8/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8125 - loss: 0.5759 - val_accuracy: 0.2381 - val_loss: 1.6174\n",
      "Epoch 9/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9068 - loss: 0.4216 - val_accuracy: 0.1429 - val_loss: 1.8918\n",
      "Epoch 10/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8771 - loss: 0.3666 - val_accuracy: 0.2381 - val_loss: 1.9761\n",
      "Epoch 11/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9128 - loss: 0.2830 - val_accuracy: 0.2857 - val_loss: 2.0621\n",
      "Epoch 12/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9657 - loss: 0.2299 - val_accuracy: 0.1905 - val_loss: 2.2503\n",
      "Epoch 13/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9851 - loss: 0.1461 - val_accuracy: 0.3810 - val_loss: 2.3010\n",
      "Epoch 14/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9861 - loss: 0.1086 - val_accuracy: 0.1905 - val_loss: 2.7913\n",
      "Epoch 15/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0790 - val_accuracy: 0.2857 - val_loss: 2.9220\n",
      "Epoch 16/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0589 - val_accuracy: 0.2857 - val_loss: 3.0351\n",
      "Epoch 17/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0462 - val_accuracy: 0.2857 - val_loss: 3.3384\n",
      "Epoch 18/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0317 - val_accuracy: 0.2857 - val_loss: 3.3903\n",
      "Epoch 19/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0201 - val_accuracy: 0.3333 - val_loss: 3.4005\n",
      "Epoch 20/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0149 - val_accuracy: 0.3810 - val_loss: 3.4524\n",
      "Epoch 21/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0107 - val_accuracy: 0.2381 - val_loss: 3.5915\n",
      "Epoch 22/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0116 - val_accuracy: 0.3333 - val_loss: 3.6599\n",
      "Epoch 23/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0102 - val_accuracy: 0.2857 - val_loss: 3.7746\n",
      "Epoch 24/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0073 - val_accuracy: 0.2381 - val_loss: 3.8708\n",
      "Epoch 25/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 0.2857 - val_loss: 3.8467\n",
      "Epoch 26/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 0.2857 - val_loss: 3.8259\n",
      "Epoch 27/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.2857 - val_loss: 3.8783\n",
      "Epoch 28/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.2857 - val_loss: 3.9709\n",
      "Epoch 29/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.2857 - val_loss: 4.0775\n",
      "Epoch 30/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 0.2857 - val_loss: 4.0824\n",
      "Epoch 31/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.2857 - val_loss: 4.1192\n",
      "Epoch 32/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.2857 - val_loss: 4.1714\n",
      "Epoch 33/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.2857 - val_loss: 4.2220\n",
      "Epoch 34/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.2857 - val_loss: 4.2561\n",
      "Epoch 35/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.2381 - val_loss: 4.2881\n",
      "Epoch 36/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.2381 - val_loss: 4.3060\n",
      "Epoch 37/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.2857 - val_loss: 4.3019\n",
      "Epoch 38/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.2857 - val_loss: 4.2832\n",
      "Epoch 39/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.2857 - val_loss: 4.3166\n",
      "Epoch 40/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.2857 - val_loss: 4.3857\n",
      "Epoch 41/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.2857 - val_loss: 4.4344\n",
      "Epoch 42/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.2857 - val_loss: 4.4684\n",
      "Epoch 43/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.2857 - val_loss: 4.4817\n",
      "Epoch 44/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.2857 - val_loss: 4.4843\n",
      "Epoch 45/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.2857 - val_loss: 4.4843\n",
      "Epoch 46/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.2857 - val_loss: 4.5035\n",
      "Epoch 47/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.2381 - val_loss: 4.5480\n",
      "Epoch 48/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.2381 - val_loss: 4.6027\n",
      "Epoch 49/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.2381 - val_loss: 4.6217\n",
      "Epoch 50/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.2381 - val_loss: 4.6179\n",
      "\n",
      "Acurácia no conjunto de teste: 25.93%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# === Carregar os dados ===\n",
    "file_path = './dados_funcionais_patenteadores.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# === Escolha da coluna alvo ===\n",
    "target_column = 'Nature of motivation'\n",
    "\n",
    "X = df.drop(columns=[target_column])\n",
    "y = df[target_column]\n",
    "\n",
    "# === Pré-processamento ===\n",
    "numeric_features = X.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), numeric_features),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "])\n",
    "\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "# === Codificação da variável alvo ===\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "y_categorical = to_categorical(y_encoded)\n",
    "\n",
    "# === Redimensionar X para 3D (samples, features, 1) ===\n",
    "X_reshaped = X_processed.toarray() if hasattr(X_processed, \"toarray\") else X_processed\n",
    "X_reshaped = X_reshaped.reshape((X_reshaped.shape[0], X_reshaped.shape[1], 1))\n",
    "\n",
    "# === Dividir os dados ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_categorical, test_size=0.2, random_state=42)\n",
    "\n",
    "# === Modelo CNN ===\n",
    "model = Sequential([\n",
    "    Conv1D(64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.3),\n",
    "    Conv1D(32, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(y_categorical.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# === Treinar o modelo ===\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.2, verbose=1)\n",
    "\n",
    "# === Avaliação ===\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'\\nAcurácia no conjunto de teste: {accuracy:.2%}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c38b886b-bf65-47ab-a145-c29982ac6bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - Classification_regarding_professional_orientation_accuracy: 0.2940 - Classification_regarding_professional_orientation_loss: 1.3490 - Interaction_in_patenting_process_Active_or_passive__accuracy: 0.4995 - Interaction_in_patenting_process_Active_or_passive__loss: 0.6921 - Nature_of_motivation_accuracy: 0.3782 - Nature_of_motivation_loss: 1.1010 - Relationship_between_standards_personal_values_accuracy: 0.3162 - Relationship_between_standards_personal_values_loss: 1.1018 - loss: 4.2463 - val_Classification_regarding_professional_orientation_accuracy: 0.6667 - val_Classification_regarding_professional_orientation_loss: 1.1521 - val_Interaction_in_patenting_process_Active_or_passive__accuracy: 0.5714 - val_Interaction_in_patenting_process_Active_or_passive__loss: 0.6833 - val_Nature_of_motivation_accuracy: 0.3333 - val_Nature_of_motivation_loss: 1.1045 - val_Relationship_between_standards_personal_values_accuracy: 0.4762 - val_Relationship_between_standards_personal_values_loss: 1.0806 - val_loss: 4.0235\n",
      "Epoch 2/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - Classification_regarding_professional_orientation_accuracy: 0.5519 - Classification_regarding_professional_orientation_loss: 1.1571 - Interaction_in_patenting_process_Active_or_passive__accuracy: 0.5692 - Interaction_in_patenting_process_Active_or_passive__loss: 0.6722 - Nature_of_motivation_accuracy: 0.4158 - Nature_of_motivation_loss: 1.0882 - Relationship_between_standards_personal_values_accuracy: 0.4379 - Relationship_between_standards_personal_values_loss: 1.0650 - loss: 3.9561 - val_Classification_regarding_professional_orientation_accuracy: 0.6667 - val_Classification_regarding_professional_orientation_loss: 0.9168 - val_Interaction_in_patenting_process_Active_or_passive__accuracy: 0.5714 - val_Interaction_in_patenting_process_Active_or_passive__loss: 0.6447 - val_Nature_of_motivation_accuracy: 0.2381 - val_Nature_of_motivation_loss: 1.1378 - val_Relationship_between_standards_personal_values_accuracy: 0.4286 - val_Relationship_between_standards_personal_values_loss: 1.0570 - val_loss: 3.7726\n",
      "Epoch 3/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - Classification_regarding_professional_orientation_accuracy: 0.5609 - Classification_regarding_professional_orientation_loss: 0.9971 - Interaction_in_patenting_process_Active_or_passive__accuracy: 0.5256 - Interaction_in_patenting_process_Active_or_passive__loss: 0.6698 - Nature_of_motivation_accuracy: 0.4669 - Nature_of_motivation_loss: 1.0717 - Relationship_between_standards_personal_values_accuracy: 0.4858 - Relationship_between_standards_personal_values_loss: 1.0215 - loss: 3.7572 - val_Classification_regarding_professional_orientation_accuracy: 0.6667 - val_Classification_regarding_professional_orientation_loss: 0.9140 - val_Interaction_in_patenting_process_Active_or_passive__accuracy: 0.6667 - val_Interaction_in_patenting_process_Active_or_passive__loss: 0.6636 - val_Nature_of_motivation_accuracy: 0.1905 - val_Nature_of_motivation_loss: 1.1283 - val_Relationship_between_standards_personal_values_accuracy: 0.4286 - val_Relationship_between_standards_personal_values_loss: 1.0526 - val_loss: 3.7229\n",
      "Epoch 4/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - Classification_regarding_professional_orientation_accuracy: 0.5549 - Classification_regarding_professional_orientation_loss: 1.0118 - Interaction_in_patenting_process_Active_or_passive__accuracy: 0.7844 - Interaction_in_patenting_process_Active_or_passive__loss: 0.6271 - Nature_of_motivation_accuracy: 0.5519 - Nature_of_motivation_loss: 1.0583 - Relationship_between_standards_personal_values_accuracy: 0.5344 - Relationship_between_standards_personal_values_loss: 1.0027 - loss: 3.6455 - val_Classification_regarding_professional_orientation_accuracy: 0.7143 - val_Classification_regarding_professional_orientation_loss: 0.9319 - val_Interaction_in_patenting_process_Active_or_passive__accuracy: 0.6190 - val_Interaction_in_patenting_process_Active_or_passive__loss: 0.7406 - val_Nature_of_motivation_accuracy: 0.2857 - val_Nature_of_motivation_loss: 1.1155 - val_Relationship_between_standards_personal_values_accuracy: 0.3810 - val_Relationship_between_standards_personal_values_loss: 1.0766 - val_loss: 3.7111\n",
      "Epoch 5/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - Classification_regarding_professional_orientation_accuracy: 0.6023 - Classification_regarding_professional_orientation_loss: 0.9195 - Interaction_in_patenting_process_Active_or_passive__accuracy: 0.7320 - Interaction_in_patenting_process_Active_or_passive__loss: 0.5808 - Nature_of_motivation_accuracy: 0.5076 - Nature_of_motivation_loss: 1.0324 - Relationship_between_standards_personal_values_accuracy: 0.5999 - Relationship_between_standards_personal_values_loss: 0.9487 - loss: 3.4955 - val_Classification_regarding_professional_orientation_accuracy: 0.7143 - val_Classification_regarding_professional_orientation_loss: 0.8896 - val_Interaction_in_patenting_process_Active_or_passive__accuracy: 0.6667 - val_Interaction_in_patenting_process_Active_or_passive__loss: 0.6819 - val_Nature_of_motivation_accuracy: 0.4286 - val_Nature_of_motivation_loss: 1.1639 - val_Relationship_between_standards_personal_values_accuracy: 0.3810 - val_Relationship_between_standards_personal_values_loss: 1.0801 - val_loss: 3.6802\n",
      "Epoch 6/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - Classification_regarding_professional_orientation_accuracy: 0.6232 - Classification_regarding_professional_orientation_loss: 0.9331 - Interaction_in_patenting_process_Active_or_passive__accuracy: 0.7690 - Interaction_in_patenting_process_Active_or_passive__loss: 0.5409 - Nature_of_motivation_accuracy: 0.4101 - Nature_of_motivation_loss: 1.0068 - Relationship_between_standards_personal_values_accuracy: 0.6510 - Relationship_between_standards_personal_values_loss: 0.8824 - loss: 3.3821 - val_Classification_regarding_professional_orientation_accuracy: 0.7143 - val_Classification_regarding_professional_orientation_loss: 0.8481 - val_Interaction_in_patenting_process_Active_or_passive__accuracy: 0.6667 - val_Interaction_in_patenting_process_Active_or_passive__loss: 0.6601 - val_Nature_of_motivation_accuracy: 0.3333 - val_Nature_of_motivation_loss: 1.1965 - val_Relationship_between_standards_personal_values_accuracy: 0.3810 - val_Relationship_between_standards_personal_values_loss: 1.0800 - val_loss: 3.6555\n",
      "Epoch 7/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - Classification_regarding_professional_orientation_accuracy: 0.6210 - Classification_regarding_professional_orientation_loss: 0.9086 - Interaction_in_patenting_process_Active_or_passive__accuracy: 0.8169 - Interaction_in_patenting_process_Active_or_passive__loss: 0.4984 - Nature_of_motivation_accuracy: 0.5997 - Nature_of_motivation_loss: 0.9589 - Relationship_between_standards_personal_values_accuracy: 0.6610 - Relationship_between_standards_personal_values_loss: 0.8390 - loss: 3.1946 - val_Classification_regarding_professional_orientation_accuracy: 0.7143 - val_Classification_regarding_professional_orientation_loss: 0.8407 - val_Interaction_in_patenting_process_Active_or_passive__accuracy: 0.6667 - val_Interaction_in_patenting_process_Active_or_passive__loss: 0.7318 - val_Nature_of_motivation_accuracy: 0.2381 - val_Nature_of_motivation_loss: 1.2282 - val_Relationship_between_standards_personal_values_accuracy: 0.2381 - val_Relationship_between_standards_personal_values_loss: 1.1168 - val_loss: 3.7225\n",
      "Epoch 8/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - Classification_regarding_professional_orientation_accuracy: 0.6776 - Classification_regarding_professional_orientation_loss: 0.8075 - Interaction_in_patenting_process_Active_or_passive__accuracy: 0.8296 - Interaction_in_patenting_process_Active_or_passive__loss: 0.4535 - Nature_of_motivation_accuracy: 0.6922 - Nature_of_motivation_loss: 0.8867 - Relationship_between_standards_personal_values_accuracy: 0.7271 - Relationship_between_standards_personal_values_loss: 0.7714 - loss: 2.9076 - val_Classification_regarding_professional_orientation_accuracy: 0.6667 - val_Classification_regarding_professional_orientation_loss: 0.8496 - val_Interaction_in_patenting_process_Active_or_passive__accuracy: 0.6667 - val_Interaction_in_patenting_process_Active_or_passive__loss: 0.8025 - val_Nature_of_motivation_accuracy: 0.2381 - val_Nature_of_motivation_loss: 1.2558 - val_Relationship_between_standards_personal_values_accuracy: 0.2857 - val_Relationship_between_standards_personal_values_loss: 1.2190 - val_loss: 3.8498\n",
      "Epoch 9/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - Classification_regarding_professional_orientation_accuracy: 0.6962 - Classification_regarding_professional_orientation_loss: 0.7359 - Interaction_in_patenting_process_Active_or_passive__accuracy: 0.8132 - Interaction_in_patenting_process_Active_or_passive__loss: 0.4289 - Nature_of_motivation_accuracy: 0.7011 - Nature_of_motivation_loss: 0.8342 - Relationship_between_standards_personal_values_accuracy: 0.7213 - Relationship_between_standards_personal_values_loss: 0.6911 - loss: 2.6756 - val_Classification_regarding_professional_orientation_accuracy: 0.6667 - val_Classification_regarding_professional_orientation_loss: 0.7869 - val_Interaction_in_patenting_process_Active_or_passive__accuracy: 0.5714 - val_Interaction_in_patenting_process_Active_or_passive__loss: 0.9246 - val_Nature_of_motivation_accuracy: 0.2857 - val_Nature_of_motivation_loss: 1.3028 - val_Relationship_between_standards_personal_values_accuracy: 0.2857 - val_Relationship_between_standards_personal_values_loss: 1.3125 - val_loss: 3.9661\n",
      "Epoch 10/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - Classification_regarding_professional_orientation_accuracy: 0.6973 - Classification_regarding_professional_orientation_loss: 0.7649 - Interaction_in_patenting_process_Active_or_passive__accuracy: 0.8360 - Interaction_in_patenting_process_Active_or_passive__loss: 0.3905 - Nature_of_motivation_accuracy: 0.7787 - Nature_of_motivation_loss: 0.7657 - Relationship_between_standards_personal_values_accuracy: 0.7775 - Relationship_between_standards_personal_values_loss: 0.6344 - loss: 2.4977 - val_Classification_regarding_professional_orientation_accuracy: 0.7143 - val_Classification_regarding_professional_orientation_loss: 0.7155 - val_Interaction_in_patenting_process_Active_or_passive__accuracy: 0.5714 - val_Interaction_in_patenting_process_Active_or_passive__loss: 0.8838 - val_Nature_of_motivation_accuracy: 0.2857 - val_Nature_of_motivation_loss: 1.3632 - val_Relationship_between_standards_personal_values_accuracy: 0.2857 - val_Relationship_between_standards_personal_values_loss: 1.3669 - val_loss: 4.1501\n",
      "Epoch 11/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - Classification_regarding_professional_orientation_accuracy: 0.8135 - Classification_regarding_professional_orientation_loss: 0.6273 - Interaction_in_patenting_process_Active_or_passive__accuracy: 0.8818 - Interaction_in_patenting_process_Active_or_passive__loss: 0.3163 - Nature_of_motivation_accuracy: 0.6907 - Nature_of_motivation_loss: 0.7151 - Relationship_between_standards_personal_values_accuracy: 0.7697 - Relationship_between_standards_personal_values_loss: 0.5604 - loss: 2.2050 - val_Classification_regarding_professional_orientation_accuracy: 0.7143 - val_Classification_regarding_professional_orientation_loss: 0.7239 - val_Interaction_in_patenting_process_Active_or_passive__accuracy: 0.5714 - val_Interaction_in_patenting_process_Active_or_passive__loss: 1.0591 - val_Nature_of_motivation_accuracy: 0.1905 - val_Nature_of_motivation_loss: 1.5599 - val_Relationship_between_standards_personal_values_accuracy: 0.3810 - val_Relationship_between_standards_personal_values_loss: 1.4025 - val_loss: 4.5347\n",
      "Epoch 12/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - Classification_regarding_professional_orientation_accuracy: 0.7245 - Classification_regarding_professional_orientation_loss: 0.6019 - Interaction_in_patenting_process_Active_or_passive__accuracy: 0.9351 - Interaction_in_patenting_process_Active_or_passive__loss: 0.2914 - Nature_of_motivation_accuracy: 0.8110 - Nature_of_motivation_loss: 0.6421 - Relationship_between_standards_personal_values_accuracy: 0.8227 - Relationship_between_standards_personal_values_loss: 0.5268 - loss: 2.0583 - val_Classification_regarding_professional_orientation_accuracy: 0.7619 - val_Classification_regarding_professional_orientation_loss: 0.6953 - val_Interaction_in_patenting_process_Active_or_passive__accuracy: 0.5238 - val_Interaction_in_patenting_process_Active_or_passive__loss: 1.2007 - val_Nature_of_motivation_accuracy: 0.2381 - val_Nature_of_motivation_loss: 1.5846 - val_Relationship_between_standards_personal_values_accuracy: 0.3333 - val_Relationship_between_standards_personal_values_loss: 1.5655 - val_loss: 4.6955\n",
      "Epoch 13/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - Classification_regarding_professional_orientation_accuracy: 0.8415 - Classification_regarding_professional_orientation_loss: 0.5231 - Interaction_in_patenting_process_Active_or_passive__accuracy: 0.9404 - Interaction_in_patenting_process_Active_or_passive__loss: 0.2485 - Nature_of_motivation_accuracy: 0.8308 - Nature_of_motivation_loss: 0.5700 - Relationship_between_standards_personal_values_accuracy: 0.8914 - Relationship_between_standards_personal_values_loss: 0.3902 - loss: 1.7380 - val_Classification_regarding_professional_orientation_accuracy: 0.7143 - val_Classification_regarding_professional_orientation_loss: 0.6325 - val_Interaction_in_patenting_process_Active_or_passive__accuracy: 0.4286 - val_Interaction_in_patenting_process_Active_or_passive__loss: 1.4682 - val_Nature_of_motivation_accuracy: 0.2857 - val_Nature_of_motivation_loss: 1.6745 - val_Relationship_between_standards_personal_values_accuracy: 0.3333 - val_Relationship_between_standards_personal_values_loss: 1.8353 - val_loss: 5.0666\n",
      "Epoch 14/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - Classification_regarding_professional_orientation_accuracy: 0.8713 - Classification_regarding_professional_orientation_loss: 0.4140 - Interaction_in_patenting_process_Active_or_passive__accuracy: 0.9374 - Interaction_in_patenting_process_Active_or_passive__loss: 0.2210 - Nature_of_motivation_accuracy: 0.8315 - Nature_of_motivation_loss: 0.5035 - Relationship_between_standards_personal_values_accuracy: 0.9026 - Relationship_between_standards_personal_values_loss: 0.3207 - loss: 1.4339 - val_Classification_regarding_professional_orientation_accuracy: 0.7619 - val_Classification_regarding_professional_orientation_loss: 0.6486 - val_Interaction_in_patenting_process_Active_or_passive__accuracy: 0.4762 - val_Interaction_in_patenting_process_Active_or_passive__loss: 1.4846 - val_Nature_of_motivation_accuracy: 0.1905 - val_Nature_of_motivation_loss: 1.9161 - val_Relationship_between_standards_personal_values_accuracy: 0.3333 - val_Relationship_between_standards_personal_values_loss: 1.8638 - val_loss: 5.5607\n",
      "Epoch 15/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - Classification_regarding_professional_orientation_accuracy: 0.8878 - Classification_regarding_professional_orientation_loss: 0.3861 - Interaction_in_patenting_process_Active_or_passive__accuracy: 0.9419 - Interaction_in_patenting_process_Active_or_passive__loss: 0.1919 - Nature_of_motivation_accuracy: 0.9198 - Nature_of_motivation_loss: 0.4021 - Relationship_between_standards_personal_values_accuracy: 0.9613 - Relationship_between_standards_personal_values_loss: 0.2818 - loss: 1.2477 - val_Classification_regarding_professional_orientation_accuracy: 0.7143 - val_Classification_regarding_professional_orientation_loss: 0.6301 - val_Interaction_in_patenting_process_Active_or_passive__accuracy: 0.4762 - val_Interaction_in_patenting_process_Active_or_passive__loss: 1.8589 - val_Nature_of_motivation_accuracy: 0.2857 - val_Nature_of_motivation_loss: 1.9132 - val_Relationship_between_standards_personal_values_accuracy: 0.2381 - val_Relationship_between_standards_personal_values_loss: 2.0599 - val_loss: 5.8655\n",
      "Epoch 16/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - Classification_regarding_professional_orientation_accuracy: 0.9277 - Classification_regarding_professional_orientation_loss: 0.2930 - Interaction_in_patenting_process_Active_or_passive__accuracy: 0.9553 - Interaction_in_patenting_process_Active_or_passive__loss: 0.1517 - Nature_of_motivation_accuracy: 0.9508 - Nature_of_motivation_loss: 0.3435 - Relationship_between_standards_personal_values_accuracy: 0.9113 - Relationship_between_standards_personal_values_loss: 0.2556 - loss: 1.0564 - val_Classification_regarding_professional_orientation_accuracy: 0.7143 - val_Classification_regarding_professional_orientation_loss: 0.6374 - val_Interaction_in_patenting_process_Active_or_passive__accuracy: 0.4286 - val_Interaction_in_patenting_process_Active_or_passive__loss: 1.8302 - val_Nature_of_motivation_accuracy: 0.2381 - val_Nature_of_motivation_loss: 2.1340 - val_Relationship_between_standards_personal_values_accuracy: 0.3810 - val_Relationship_between_standards_personal_values_loss: 2.2346 - val_loss: 6.4613\n",
      "Epoch 17/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - Classification_regarding_professional_orientation_accuracy: 0.9724 - Classification_regarding_professional_orientation_loss: 0.2376 - Interaction_in_patenting_process_Active_or_passive__accuracy: 0.9851 - Interaction_in_patenting_process_Active_or_passive__loss: 0.1171 - Nature_of_motivation_accuracy: 0.9374 - Nature_of_motivation_loss: 0.3227 - Relationship_between_standards_personal_values_accuracy: 0.9762 - Relationship_between_standards_personal_values_loss: 0.1677 - loss: 0.8457 - val_Classification_regarding_professional_orientation_accuracy: 0.6667 - val_Classification_regarding_professional_orientation_loss: 0.6899 - val_Interaction_in_patenting_process_Active_or_passive__accuracy: 0.4286 - val_Interaction_in_patenting_process_Active_or_passive__loss: 1.9782 - val_Nature_of_motivation_accuracy: 0.1905 - val_Nature_of_motivation_loss: 2.2784 - val_Relationship_between_standards_personal_values_accuracy: 0.2857 - val_Relationship_between_standards_personal_values_loss: 2.4185 - val_loss: 7.0278\n",
      "Epoch 18/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - Classification_regarding_professional_orientation_accuracy: 0.9613 - Classification_regarding_professional_orientation_loss: 0.2005 - Interaction_in_patenting_process_Active_or_passive__accuracy: 0.9523 - Interaction_in_patenting_process_Active_or_passive__loss: 0.1245 - Nature_of_motivation_accuracy: 0.9709 - Nature_of_motivation_loss: 0.2028 - Relationship_between_standards_personal_values_accuracy: 0.9925 - Relationship_between_standards_personal_values_loss: 0.1238 - loss: 0.6692 - val_Classification_regarding_professional_orientation_accuracy: 0.7143 - val_Classification_regarding_professional_orientation_loss: 0.8174 - val_Interaction_in_patenting_process_Active_or_passive__accuracy: 0.4286 - val_Interaction_in_patenting_process_Active_or_passive__loss: 2.4818 - val_Nature_of_motivation_accuracy: 0.1905 - val_Nature_of_motivation_loss: 2.3980 - val_Relationship_between_standards_personal_values_accuracy: 0.3333 - val_Relationship_between_standards_personal_values_loss: 2.6854 - val_loss: 7.7467\n",
      "Epoch 19/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - Classification_regarding_professional_orientation_accuracy: 1.0000 - Classification_regarding_professional_orientation_loss: 0.1511 - Interaction_in_patenting_process_Active_or_passive__accuracy: 0.9851 - Interaction_in_patenting_process_Active_or_passive__loss: 0.0685 - Nature_of_motivation_accuracy: 0.9851 - Nature_of_motivation_loss: 0.1976 - Relationship_between_standards_personal_values_accuracy: 0.9896 - Relationship_between_standards_personal_values_loss: 0.0922 - loss: 0.5150 - val_Classification_regarding_professional_orientation_accuracy: 0.7143 - val_Classification_regarding_professional_orientation_loss: 0.8294 - val_Interaction_in_patenting_process_Active_or_passive__accuracy: 0.4286 - val_Interaction_in_patenting_process_Active_or_passive__loss: 2.5525 - val_Nature_of_motivation_accuracy: 0.1905 - val_Nature_of_motivation_loss: 2.4916 - val_Relationship_between_standards_personal_values_accuracy: 0.3333 - val_Relationship_between_standards_personal_values_loss: 3.0231 - val_loss: 8.2893\n",
      "Epoch 20/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - Classification_regarding_professional_orientation_accuracy: 0.9896 - Classification_regarding_professional_orientation_loss: 0.1005 - Interaction_in_patenting_process_Active_or_passive__accuracy: 1.0000 - Interaction_in_patenting_process_Active_or_passive__loss: 0.0426 - Nature_of_motivation_accuracy: 1.0000 - Nature_of_motivation_loss: 0.1253 - Relationship_between_standards_personal_values_accuracy: 1.0000 - Relationship_between_standards_personal_values_loss: 0.0550 - loss: 0.3350 - val_Classification_regarding_professional_orientation_accuracy: 0.6667 - val_Classification_regarding_professional_orientation_loss: 0.8613 - val_Interaction_in_patenting_process_Active_or_passive__accuracy: 0.4286 - val_Interaction_in_patenting_process_Active_or_passive__loss: 2.6333 - val_Nature_of_motivation_accuracy: 0.1905 - val_Nature_of_motivation_loss: 2.6477 - val_Relationship_between_standards_personal_values_accuracy: 0.3333 - val_Relationship_between_standards_personal_values_loss: 3.2615 - val_loss: 8.8682\n",
      "Epoch 21/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - Classification_regarding_professional_orientation_accuracy: 1.0000 - Classification_regarding_professional_orientation_loss: 0.0866 - Interaction_in_patenting_process_Active_or_passive__accuracy: 0.9851 - Interaction_in_patenting_process_Active_or_passive__loss: 0.0484 - Nature_of_motivation_accuracy: 1.0000 - Nature_of_motivation_loss: 0.1136 - Relationship_between_standards_personal_values_accuracy: 1.0000 - Relationship_between_standards_personal_values_loss: 0.0441 - loss: 0.2933 - val_Classification_regarding_professional_orientation_accuracy: 0.6667 - val_Classification_regarding_professional_orientation_loss: 0.9034 - val_Interaction_in_patenting_process_Active_or_passive__accuracy: 0.4286 - val_Interaction_in_patenting_process_Active_or_passive__loss: 3.1442 - val_Nature_of_motivation_accuracy: 0.1905 - val_Nature_of_motivation_loss: 2.7980 - val_Relationship_between_standards_personal_values_accuracy: 0.3333 - val_Relationship_between_standards_personal_values_loss: 3.3938 - val_loss: 9.4424\n",
      "Epoch 22/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - Classification_regarding_professional_orientation_accuracy: 1.0000 - Classification_regarding_professional_orientation_loss: 0.0577 - Interaction_in_patenting_process_Active_or_passive__accuracy: 1.0000 - Interaction_in_patenting_process_Active_or_passive__loss: 0.0318 - Nature_of_motivation_accuracy: 1.0000 - Nature_of_motivation_loss: 0.0733 - Relationship_between_standards_personal_values_accuracy: 1.0000 - Relationship_between_standards_personal_values_loss: 0.0301 - loss: 0.1978 - val_Classification_regarding_professional_orientation_accuracy: 0.6190 - val_Classification_regarding_professional_orientation_loss: 0.9599 - val_Interaction_in_patenting_process_Active_or_passive__accuracy: 0.4286 - val_Interaction_in_patenting_process_Active_or_passive__loss: 3.2241 - val_Nature_of_motivation_accuracy: 0.2381 - val_Nature_of_motivation_loss: 2.8305 - val_Relationship_between_standards_personal_values_accuracy: 0.3333 - val_Relationship_between_standards_personal_values_loss: 3.6007 - val_loss: 9.7556\n",
      "Epoch 23/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - Classification_regarding_professional_orientation_accuracy: 1.0000 - Classification_regarding_professional_orientation_loss: 0.0583 - Interaction_in_patenting_process_Active_or_passive__accuracy: 1.0000 - Interaction_in_patenting_process_Active_or_passive__loss: 0.0248 - Nature_of_motivation_accuracy: 1.0000 - Nature_of_motivation_loss: 0.0769 - Relationship_between_standards_personal_values_accuracy: 1.0000 - Relationship_between_standards_personal_values_loss: 0.0282 - loss: 0.1886 - val_Classification_regarding_professional_orientation_accuracy: 0.6190 - val_Classification_regarding_professional_orientation_loss: 0.9772 - val_Interaction_in_patenting_process_Active_or_passive__accuracy: 0.4286 - val_Interaction_in_patenting_process_Active_or_passive__loss: 3.2019 - val_Nature_of_motivation_accuracy: 0.1905 - val_Nature_of_motivation_loss: 3.0757 - val_Relationship_between_standards_personal_values_accuracy: 0.3333 - val_Relationship_between_standards_personal_values_loss: 3.7929 - val_loss: 10.3112\n",
      "Epoch 24/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - Classification_regarding_professional_orientation_accuracy: 1.0000 - Classification_regarding_professional_orientation_loss: 0.0449 - Interaction_in_patenting_process_Active_or_passive__accuracy: 1.0000 - Interaction_in_patenting_process_Active_or_passive__loss: 0.0284 - Nature_of_motivation_accuracy: 1.0000 - Nature_of_motivation_loss: 0.0541 - Relationship_between_standards_personal_values_accuracy: 1.0000 - Relationship_between_standards_personal_values_loss: 0.0230 - loss: 0.1513 - val_Classification_regarding_professional_orientation_accuracy: 0.6190 - val_Classification_regarding_professional_orientation_loss: 1.0360 - val_Interaction_in_patenting_process_Active_or_passive__accuracy: 0.4762 - val_Interaction_in_patenting_process_Active_or_passive__loss: 3.5420 - val_Nature_of_motivation_accuracy: 0.1905 - val_Nature_of_motivation_loss: 3.2436 - val_Relationship_between_standards_personal_values_accuracy: 0.3333 - val_Relationship_between_standards_personal_values_loss: 3.9258 - val_loss: 10.8417\n",
      "Epoch 25/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - Classification_regarding_professional_orientation_accuracy: 1.0000 - Classification_regarding_professional_orientation_loss: 0.0336 - Interaction_in_patenting_process_Active_or_passive__accuracy: 1.0000 - Interaction_in_patenting_process_Active_or_passive__loss: 0.0169 - Nature_of_motivation_accuracy: 1.0000 - Nature_of_motivation_loss: 0.0423 - Relationship_between_standards_personal_values_accuracy: 1.0000 - Relationship_between_standards_personal_values_loss: 0.0159 - loss: 0.1088 - val_Classification_regarding_professional_orientation_accuracy: 0.6190 - val_Classification_regarding_professional_orientation_loss: 1.0507 - val_Interaction_in_patenting_process_Active_or_passive__accuracy: 0.4286 - val_Interaction_in_patenting_process_Active_or_passive__loss: 3.6163 - val_Nature_of_motivation_accuracy: 0.1905 - val_Nature_of_motivation_loss: 3.3394 - val_Relationship_between_standards_personal_values_accuracy: 0.2857 - val_Relationship_between_standards_personal_values_loss: 4.0423 - val_loss: 11.1731\n",
      "Epoch 26/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - Classification_regarding_professional_orientation_accuracy: 1.0000 - Classification_regarding_professional_orientation_loss: 0.0371 - Interaction_in_patenting_process_Active_or_passive__accuracy: 1.0000 - Interaction_in_patenting_process_Active_or_passive__loss: 0.0206 - Nature_of_motivation_accuracy: 1.0000 - Nature_of_motivation_loss: 0.0358 - Relationship_between_standards_personal_values_accuracy: 1.0000 - Relationship_between_standards_personal_values_loss: 0.0175 - loss: 0.1128 - val_Classification_regarding_professional_orientation_accuracy: 0.6190 - val_Classification_regarding_professional_orientation_loss: 1.0704 - val_Interaction_in_patenting_process_Active_or_passive__accuracy: 0.4286 - val_Interaction_in_patenting_process_Active_or_passive__loss: 3.6759 - val_Nature_of_motivation_accuracy: 0.1905 - val_Nature_of_motivation_loss: 3.4407 - val_Relationship_between_standards_personal_values_accuracy: 0.2857 - val_Relationship_between_standards_personal_values_loss: 4.1710 - val_loss: 11.5698\n",
      "Epoch 27/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - Classification_regarding_professional_orientation_accuracy: 1.0000 - Classification_regarding_professional_orientation_loss: 0.0227 - Interaction_in_patenting_process_Active_or_passive__accuracy: 1.0000 - Interaction_in_patenting_process_Active_or_passive__loss: 0.0093 - Nature_of_motivation_accuracy: 1.0000 - Nature_of_motivation_loss: 0.0271 - Relationship_between_standards_personal_values_accuracy: 1.0000 - Relationship_between_standards_personal_values_loss: 0.0117 - loss: 0.0734 - val_Classification_regarding_professional_orientation_accuracy: 0.6190 - val_Classification_regarding_professional_orientation_loss: 1.1188 - val_Interaction_in_patenting_process_Active_or_passive__accuracy: 0.3333 - val_Interaction_in_patenting_process_Active_or_passive__loss: 4.0037 - val_Nature_of_motivation_accuracy: 0.1905 - val_Nature_of_motivation_loss: 3.5390 - val_Relationship_between_standards_personal_values_accuracy: 0.2857 - val_Relationship_between_standards_personal_values_loss: 4.2610 - val_loss: 11.9616\n",
      "Epoch 28/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - Classification_regarding_professional_orientation_accuracy: 1.0000 - Classification_regarding_professional_orientation_loss: 0.0210 - Interaction_in_patenting_process_Active_or_passive__accuracy: 1.0000 - Interaction_in_patenting_process_Active_or_passive__loss: 0.0156 - Nature_of_motivation_accuracy: 1.0000 - Nature_of_motivation_loss: 0.0245 - Relationship_between_standards_personal_values_accuracy: 1.0000 - Relationship_between_standards_personal_values_loss: 0.0098 - loss: 0.0724 - val_Classification_regarding_professional_orientation_accuracy: 0.6190 - val_Classification_regarding_professional_orientation_loss: 1.1651 - val_Interaction_in_patenting_process_Active_or_passive__accuracy: 0.3810 - val_Interaction_in_patenting_process_Active_or_passive__loss: 4.0369 - val_Nature_of_motivation_accuracy: 0.1905 - val_Nature_of_motivation_loss: 3.6196 - val_Relationship_between_standards_personal_values_accuracy: 0.2857 - val_Relationship_between_standards_personal_values_loss: 4.3928 - val_loss: 12.2739\n",
      "Epoch 29/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - Classification_regarding_professional_orientation_accuracy: 1.0000 - Classification_regarding_professional_orientation_loss: 0.0189 - Interaction_in_patenting_process_Active_or_passive__accuracy: 1.0000 - Interaction_in_patenting_process_Active_or_passive__loss: 0.0116 - Nature_of_motivation_accuracy: 1.0000 - Nature_of_motivation_loss: 0.0203 - Relationship_between_standards_personal_values_accuracy: 1.0000 - Relationship_between_standards_personal_values_loss: 0.0068 - loss: 0.0580 - val_Classification_regarding_professional_orientation_accuracy: 0.6190 - val_Classification_regarding_professional_orientation_loss: 1.2006 - val_Interaction_in_patenting_process_Active_or_passive__accuracy: 0.3810 - val_Interaction_in_patenting_process_Active_or_passive__loss: 4.1311 - val_Nature_of_motivation_accuracy: 0.2381 - val_Nature_of_motivation_loss: 3.6415 - val_Relationship_between_standards_personal_values_accuracy: 0.2857 - val_Relationship_between_standards_personal_values_loss: 4.5164 - val_loss: 12.5065\n",
      "Epoch 30/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - Classification_regarding_professional_orientation_accuracy: 1.0000 - Classification_regarding_professional_orientation_loss: 0.0151 - Interaction_in_patenting_process_Active_or_passive__accuracy: 1.0000 - Interaction_in_patenting_process_Active_or_passive__loss: 0.0095 - Nature_of_motivation_accuracy: 1.0000 - Nature_of_motivation_loss: 0.0197 - Relationship_between_standards_personal_values_accuracy: 1.0000 - Relationship_between_standards_personal_values_loss: 0.0086 - loss: 0.0519 - val_Classification_regarding_professional_orientation_accuracy: 0.6667 - val_Classification_regarding_professional_orientation_loss: 1.2699 - val_Interaction_in_patenting_process_Active_or_passive__accuracy: 0.3810 - val_Interaction_in_patenting_process_Active_or_passive__loss: 4.2245 - val_Nature_of_motivation_accuracy: 0.2381 - val_Nature_of_motivation_loss: 3.7288 - val_Relationship_between_standards_personal_values_accuracy: 0.2857 - val_Relationship_between_standards_personal_values_loss: 4.5974 - val_loss: 12.8391\n",
      "Epoch 31/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - Classification_regarding_professional_orientation_accuracy: 1.0000 - Classification_regarding_professional_orientation_loss: 0.0128 - Interaction_in_patenting_process_Active_or_passive__accuracy: 1.0000 - Interaction_in_patenting_process_Active_or_passive__loss: 0.0063 - Nature_of_motivation_accuracy: 1.0000 - Nature_of_motivation_loss: 0.0175 - Relationship_between_standards_personal_values_accuracy: 1.0000 - Relationship_between_standards_personal_values_loss: 0.0062 - loss: 0.0432 - val_Classification_regarding_professional_orientation_accuracy: 0.7143 - val_Classification_regarding_professional_orientation_loss: 1.3050 - val_Interaction_in_patenting_process_Active_or_passive__accuracy: 0.3810 - val_Interaction_in_patenting_process_Active_or_passive__loss: 4.1982 - val_Nature_of_motivation_accuracy: 0.1905 - val_Nature_of_motivation_loss: 3.8691 - val_Relationship_between_standards_personal_values_accuracy: 0.2857 - val_Relationship_between_standards_personal_values_loss: 4.6774 - val_loss: 13.1097\n",
      "Epoch 32/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - Classification_regarding_professional_orientation_accuracy: 1.0000 - Classification_regarding_professional_orientation_loss: 0.0133 - Interaction_in_patenting_process_Active_or_passive__accuracy: 1.0000 - Interaction_in_patenting_process_Active_or_passive__loss: 0.0061 - Nature_of_motivation_accuracy: 1.0000 - Nature_of_motivation_loss: 0.0137 - Relationship_between_standards_personal_values_accuracy: 1.0000 - Relationship_between_standards_personal_values_loss: 0.0068 - loss: 0.0410 - val_Classification_regarding_professional_orientation_accuracy: 0.6667 - val_Classification_regarding_professional_orientation_loss: 1.3061 - val_Interaction_in_patenting_process_Active_or_passive__accuracy: 0.3810 - val_Interaction_in_patenting_process_Active_or_passive__loss: 4.3616 - val_Nature_of_motivation_accuracy: 0.1905 - val_Nature_of_motivation_loss: 3.8877 - val_Relationship_between_standards_personal_values_accuracy: 0.2857 - val_Relationship_between_standards_personal_values_loss: 4.7253 - val_loss: 13.2438\n",
      "Epoch 33/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - Classification_regarding_professional_orientation_accuracy: 1.0000 - Classification_regarding_professional_orientation_loss: 0.0132 - Interaction_in_patenting_process_Active_or_passive__accuracy: 1.0000 - Interaction_in_patenting_process_Active_or_passive__loss: 0.0041 - Nature_of_motivation_accuracy: 1.0000 - Nature_of_motivation_loss: 0.0127 - Relationship_between_standards_personal_values_accuracy: 1.0000 - Relationship_between_standards_personal_values_loss: 0.0058 - loss: 0.0356 - val_Classification_regarding_professional_orientation_accuracy: 0.6190 - val_Classification_regarding_professional_orientation_loss: 1.3082 - val_Interaction_in_patenting_process_Active_or_passive__accuracy: 0.3810 - val_Interaction_in_patenting_process_Active_or_passive__loss: 4.5440 - val_Nature_of_motivation_accuracy: 0.1905 - val_Nature_of_motivation_loss: 3.8623 - val_Relationship_between_standards_personal_values_accuracy: 0.2857 - val_Relationship_between_standards_personal_values_loss: 4.7707 - val_loss: 13.3841\n",
      "Epoch 34/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - Classification_regarding_professional_orientation_accuracy: 1.0000 - Classification_regarding_professional_orientation_loss: 0.0108 - Interaction_in_patenting_process_Active_or_passive__accuracy: 1.0000 - Interaction_in_patenting_process_Active_or_passive__loss: 0.0042 - Nature_of_motivation_accuracy: 1.0000 - Nature_of_motivation_loss: 0.0116 - Relationship_between_standards_personal_values_accuracy: 1.0000 - Relationship_between_standards_personal_values_loss: 0.0049 - loss: 0.0312 - val_Classification_regarding_professional_orientation_accuracy: 0.7143 - val_Classification_regarding_professional_orientation_loss: 1.3463 - val_Interaction_in_patenting_process_Active_or_passive__accuracy: 0.3333 - val_Interaction_in_patenting_process_Active_or_passive__loss: 4.7389 - val_Nature_of_motivation_accuracy: 0.2381 - val_Nature_of_motivation_loss: 3.9212 - val_Relationship_between_standards_personal_values_accuracy: 0.2857 - val_Relationship_between_standards_personal_values_loss: 4.8319 - val_loss: 13.7533\n",
      "Epoch 35/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - Classification_regarding_professional_orientation_accuracy: 1.0000 - Classification_regarding_professional_orientation_loss: 0.0108 - Interaction_in_patenting_process_Active_or_passive__accuracy: 1.0000 - Interaction_in_patenting_process_Active_or_passive__loss: 0.0054 - Nature_of_motivation_accuracy: 1.0000 - Nature_of_motivation_loss: 0.0117 - Relationship_between_standards_personal_values_accuracy: 1.0000 - Relationship_between_standards_personal_values_loss: 0.0042 - loss: 0.0328 - val_Classification_regarding_professional_orientation_accuracy: 0.7143 - val_Classification_regarding_professional_orientation_loss: 1.3706 - val_Interaction_in_patenting_process_Active_or_passive__accuracy: 0.3333 - val_Interaction_in_patenting_process_Active_or_passive__loss: 4.7064 - val_Nature_of_motivation_accuracy: 0.2381 - val_Nature_of_motivation_loss: 3.9815 - val_Relationship_between_standards_personal_values_accuracy: 0.2857 - val_Relationship_between_standards_personal_values_loss: 4.9213 - val_loss: 13.9653\n",
      "Epoch 36/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - Classification_regarding_professional_orientation_accuracy: 1.0000 - Classification_regarding_professional_orientation_loss: 0.0082 - Interaction_in_patenting_process_Active_or_passive__accuracy: 1.0000 - Interaction_in_patenting_process_Active_or_passive__loss: 0.0042 - Nature_of_motivation_accuracy: 1.0000 - Nature_of_motivation_loss: 0.0102 - Relationship_between_standards_personal_values_accuracy: 1.0000 - Relationship_between_standards_personal_values_loss: 0.0056 - loss: 0.0287 - val_Classification_regarding_professional_orientation_accuracy: 0.6190 - val_Classification_regarding_professional_orientation_loss: 1.3402 - val_Interaction_in_patenting_process_Active_or_passive__accuracy: 0.3810 - val_Interaction_in_patenting_process_Active_or_passive__loss: 4.6560 - val_Nature_of_motivation_accuracy: 0.2381 - val_Nature_of_motivation_loss: 4.0336 - val_Relationship_between_standards_personal_values_accuracy: 0.2857 - val_Relationship_between_standards_personal_values_loss: 4.9785 - val_loss: 14.0331\n",
      "Epoch 37/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - Classification_regarding_professional_orientation_accuracy: 1.0000 - Classification_regarding_professional_orientation_loss: 0.0079 - Interaction_in_patenting_process_Active_or_passive__accuracy: 1.0000 - Interaction_in_patenting_process_Active_or_passive__loss: 0.0036 - Nature_of_motivation_accuracy: 1.0000 - Nature_of_motivation_loss: 0.0078 - Relationship_between_standards_personal_values_accuracy: 1.0000 - Relationship_between_standards_personal_values_loss: 0.0038 - loss: 0.0235 - val_Classification_regarding_professional_orientation_accuracy: 0.6190 - val_Classification_regarding_professional_orientation_loss: 1.3492 - val_Interaction_in_patenting_process_Active_or_passive__accuracy: 0.3333 - val_Interaction_in_patenting_process_Active_or_passive__loss: 4.7220 - val_Nature_of_motivation_accuracy: 0.2381 - val_Nature_of_motivation_loss: 4.0515 - val_Relationship_between_standards_personal_values_accuracy: 0.2857 - val_Relationship_between_standards_personal_values_loss: 5.0139 - val_loss: 14.0877\n",
      "Epoch 38/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - Classification_regarding_professional_orientation_accuracy: 1.0000 - Classification_regarding_professional_orientation_loss: 0.0067 - Interaction_in_patenting_process_Active_or_passive__accuracy: 1.0000 - Interaction_in_patenting_process_Active_or_passive__loss: 0.0029 - Nature_of_motivation_accuracy: 1.0000 - Nature_of_motivation_loss: 0.0088 - Relationship_between_standards_personal_values_accuracy: 1.0000 - Relationship_between_standards_personal_values_loss: 0.0032 - loss: 0.0219 - val_Classification_regarding_professional_orientation_accuracy: 0.6190 - val_Classification_regarding_professional_orientation_loss: 1.3908 - val_Interaction_in_patenting_process_Active_or_passive__accuracy: 0.3810 - val_Interaction_in_patenting_process_Active_or_passive__loss: 4.9569 - val_Nature_of_motivation_accuracy: 0.1905 - val_Nature_of_motivation_loss: 4.1114 - val_Relationship_between_standards_personal_values_accuracy: 0.2857 - val_Relationship_between_standards_personal_values_loss: 5.0288 - val_loss: 14.3047\n",
      "Epoch 39/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - Classification_regarding_professional_orientation_accuracy: 1.0000 - Classification_regarding_professional_orientation_loss: 0.0057 - Interaction_in_patenting_process_Active_or_passive__accuracy: 1.0000 - Interaction_in_patenting_process_Active_or_passive__loss: 0.0034 - Nature_of_motivation_accuracy: 1.0000 - Nature_of_motivation_loss: 0.0058 - Relationship_between_standards_personal_values_accuracy: 1.0000 - Relationship_between_standards_personal_values_loss: 0.0026 - loss: 0.0177 - val_Classification_regarding_professional_orientation_accuracy: 0.6667 - val_Classification_regarding_professional_orientation_loss: 1.4178 - val_Interaction_in_patenting_process_Active_or_passive__accuracy: 0.3810 - val_Interaction_in_patenting_process_Active_or_passive__loss: 5.0411 - val_Nature_of_motivation_accuracy: 0.1905 - val_Nature_of_motivation_loss: 4.1660 - val_Relationship_between_standards_personal_values_accuracy: 0.2857 - val_Relationship_between_standards_personal_values_loss: 5.0592 - val_loss: 14.4233\n",
      "Epoch 40/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - Classification_regarding_professional_orientation_accuracy: 1.0000 - Classification_regarding_professional_orientation_loss: 0.0067 - Interaction_in_patenting_process_Active_or_passive__accuracy: 1.0000 - Interaction_in_patenting_process_Active_or_passive__loss: 0.0048 - Nature_of_motivation_accuracy: 1.0000 - Nature_of_motivation_loss: 0.0067 - Relationship_between_standards_personal_values_accuracy: 1.0000 - Relationship_between_standards_personal_values_loss: 0.0030 - loss: 0.0217 - val_Classification_regarding_professional_orientation_accuracy: 0.7143 - val_Classification_regarding_professional_orientation_loss: 1.4582 - val_Interaction_in_patenting_process_Active_or_passive__accuracy: 0.3810 - val_Interaction_in_patenting_process_Active_or_passive__loss: 4.8242 - val_Nature_of_motivation_accuracy: 0.1905 - val_Nature_of_motivation_loss: 4.2247 - val_Relationship_between_standards_personal_values_accuracy: 0.2857 - val_Relationship_between_standards_personal_values_loss: 5.1367 - val_loss: 14.5412\n",
      "Epoch 41/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - Classification_regarding_professional_orientation_accuracy: 1.0000 - Classification_regarding_professional_orientation_loss: 0.0064 - Interaction_in_patenting_process_Active_or_passive__accuracy: 1.0000 - Interaction_in_patenting_process_Active_or_passive__loss: 0.0039 - Nature_of_motivation_accuracy: 1.0000 - Nature_of_motivation_loss: 0.0068 - Relationship_between_standards_personal_values_accuracy: 1.0000 - Relationship_between_standards_personal_values_loss: 0.0033 - loss: 0.0201 - val_Classification_regarding_professional_orientation_accuracy: 0.6667 - val_Classification_regarding_professional_orientation_loss: 1.4752 - val_Interaction_in_patenting_process_Active_or_passive__accuracy: 0.3810 - val_Interaction_in_patenting_process_Active_or_passive__loss: 4.7862 - val_Nature_of_motivation_accuracy: 0.2381 - val_Nature_of_motivation_loss: 4.2645 - val_Relationship_between_standards_personal_values_accuracy: 0.2857 - val_Relationship_between_standards_personal_values_loss: 5.2193 - val_loss: 14.6831\n",
      "Epoch 42/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - Classification_regarding_professional_orientation_accuracy: 1.0000 - Classification_regarding_professional_orientation_loss: 0.0044 - Interaction_in_patenting_process_Active_or_passive__accuracy: 1.0000 - Interaction_in_patenting_process_Active_or_passive__loss: 0.0033 - Nature_of_motivation_accuracy: 1.0000 - Nature_of_motivation_loss: 0.0066 - Relationship_between_standards_personal_values_accuracy: 1.0000 - Relationship_between_standards_personal_values_loss: 0.0027 - loss: 0.0171 - val_Classification_regarding_professional_orientation_accuracy: 0.6190 - val_Classification_regarding_professional_orientation_loss: 1.4902 - val_Interaction_in_patenting_process_Active_or_passive__accuracy: 0.3810 - val_Interaction_in_patenting_process_Active_or_passive__loss: 4.8744 - val_Nature_of_motivation_accuracy: 0.2381 - val_Nature_of_motivation_loss: 4.3200 - val_Relationship_between_standards_personal_values_accuracy: 0.2857 - val_Relationship_between_standards_personal_values_loss: 5.2517 - val_loss: 14.8483\n",
      "Epoch 43/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - Classification_regarding_professional_orientation_accuracy: 1.0000 - Classification_regarding_professional_orientation_loss: 0.0037 - Interaction_in_patenting_process_Active_or_passive__accuracy: 1.0000 - Interaction_in_patenting_process_Active_or_passive__loss: 0.0029 - Nature_of_motivation_accuracy: 1.0000 - Nature_of_motivation_loss: 0.0043 - Relationship_between_standards_personal_values_accuracy: 1.0000 - Relationship_between_standards_personal_values_loss: 0.0018 - loss: 0.0124 - val_Classification_regarding_professional_orientation_accuracy: 0.6667 - val_Classification_regarding_professional_orientation_loss: 1.5303 - val_Interaction_in_patenting_process_Active_or_passive__accuracy: 0.3810 - val_Interaction_in_patenting_process_Active_or_passive__loss: 5.1176 - val_Nature_of_motivation_accuracy: 0.2381 - val_Nature_of_motivation_loss: 4.3420 - val_Relationship_between_standards_personal_values_accuracy: 0.2857 - val_Relationship_between_standards_personal_values_loss: 5.2644 - val_loss: 15.0701\n",
      "Epoch 44/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - Classification_regarding_professional_orientation_accuracy: 1.0000 - Classification_regarding_professional_orientation_loss: 0.0065 - Interaction_in_patenting_process_Active_or_passive__accuracy: 1.0000 - Interaction_in_patenting_process_Active_or_passive__loss: 0.0027 - Nature_of_motivation_accuracy: 1.0000 - Nature_of_motivation_loss: 0.0052 - Relationship_between_standards_personal_values_accuracy: 1.0000 - Relationship_between_standards_personal_values_loss: 0.0024 - loss: 0.0172 - val_Classification_regarding_professional_orientation_accuracy: 0.6190 - val_Classification_regarding_professional_orientation_loss: 1.5326 - val_Interaction_in_patenting_process_Active_or_passive__accuracy: 0.3810 - val_Interaction_in_patenting_process_Active_or_passive__loss: 5.3571 - val_Nature_of_motivation_accuracy: 0.2381 - val_Nature_of_motivation_loss: 4.3375 - val_Relationship_between_standards_personal_values_accuracy: 0.2857 - val_Relationship_between_standards_personal_values_loss: 5.2812 - val_loss: 15.2450\n",
      "Epoch 45/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - Classification_regarding_professional_orientation_accuracy: 1.0000 - Classification_regarding_professional_orientation_loss: 0.0034 - Interaction_in_patenting_process_Active_or_passive__accuracy: 1.0000 - Interaction_in_patenting_process_Active_or_passive__loss: 0.0023 - Nature_of_motivation_accuracy: 1.0000 - Nature_of_motivation_loss: 0.0052 - Relationship_between_standards_personal_values_accuracy: 1.0000 - Relationship_between_standards_personal_values_loss: 0.0025 - loss: 0.0138 - val_Classification_regarding_professional_orientation_accuracy: 0.6190 - val_Classification_regarding_professional_orientation_loss: 1.5429 - val_Interaction_in_patenting_process_Active_or_passive__accuracy: 0.3810 - val_Interaction_in_patenting_process_Active_or_passive__loss: 5.3544 - val_Nature_of_motivation_accuracy: 0.2381 - val_Nature_of_motivation_loss: 4.3369 - val_Relationship_between_standards_personal_values_accuracy: 0.2857 - val_Relationship_between_standards_personal_values_loss: 5.3268 - val_loss: 15.3170\n",
      "Epoch 46/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - Classification_regarding_professional_orientation_accuracy: 1.0000 - Classification_regarding_professional_orientation_loss: 0.0046 - Interaction_in_patenting_process_Active_or_passive__accuracy: 1.0000 - Interaction_in_patenting_process_Active_or_passive__loss: 0.0039 - Nature_of_motivation_accuracy: 1.0000 - Nature_of_motivation_loss: 0.0043 - Relationship_between_standards_personal_values_accuracy: 1.0000 - Relationship_between_standards_personal_values_loss: 0.0020 - loss: 0.0149 - val_Classification_regarding_professional_orientation_accuracy: 0.6190 - val_Classification_regarding_professional_orientation_loss: 1.5572 - val_Interaction_in_patenting_process_Active_or_passive__accuracy: 0.3810 - val_Interaction_in_patenting_process_Active_or_passive__loss: 5.2418 - val_Nature_of_motivation_accuracy: 0.2381 - val_Nature_of_motivation_loss: 4.3727 - val_Relationship_between_standards_personal_values_accuracy: 0.2857 - val_Relationship_between_standards_personal_values_loss: 5.3861 - val_loss: 15.3941\n",
      "Epoch 47/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - Classification_regarding_professional_orientation_accuracy: 1.0000 - Classification_regarding_professional_orientation_loss: 0.0035 - Interaction_in_patenting_process_Active_or_passive__accuracy: 1.0000 - Interaction_in_patenting_process_Active_or_passive__loss: 0.0019 - Nature_of_motivation_accuracy: 1.0000 - Nature_of_motivation_loss: 0.0043 - Relationship_between_standards_personal_values_accuracy: 1.0000 - Relationship_between_standards_personal_values_loss: 0.0023 - loss: 0.0122 - val_Classification_regarding_professional_orientation_accuracy: 0.6190 - val_Classification_regarding_professional_orientation_loss: 1.5765 - val_Interaction_in_patenting_process_Active_or_passive__accuracy: 0.3810 - val_Interaction_in_patenting_process_Active_or_passive__loss: 5.2951 - val_Nature_of_motivation_accuracy: 0.2381 - val_Nature_of_motivation_loss: 4.3880 - val_Relationship_between_standards_personal_values_accuracy: 0.2857 - val_Relationship_between_standards_personal_values_loss: 5.4338 - val_loss: 15.5097\n",
      "Epoch 48/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - Classification_regarding_professional_orientation_accuracy: 1.0000 - Classification_regarding_professional_orientation_loss: 0.0037 - Interaction_in_patenting_process_Active_or_passive__accuracy: 1.0000 - Interaction_in_patenting_process_Active_or_passive__loss: 0.0020 - Nature_of_motivation_accuracy: 1.0000 - Nature_of_motivation_loss: 0.0035 - Relationship_between_standards_personal_values_accuracy: 1.0000 - Relationship_between_standards_personal_values_loss: 0.0020 - loss: 0.0113 - val_Classification_regarding_professional_orientation_accuracy: 0.6190 - val_Classification_regarding_professional_orientation_loss: 1.5891 - val_Interaction_in_patenting_process_Active_or_passive__accuracy: 0.3810 - val_Interaction_in_patenting_process_Active_or_passive__loss: 5.3603 - val_Nature_of_motivation_accuracy: 0.2381 - val_Nature_of_motivation_loss: 4.4171 - val_Relationship_between_standards_personal_values_accuracy: 0.2857 - val_Relationship_between_standards_personal_values_loss: 5.4701 - val_loss: 15.6390\n",
      "Epoch 49/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - Classification_regarding_professional_orientation_accuracy: 1.0000 - Classification_regarding_professional_orientation_loss: 0.0030 - Interaction_in_patenting_process_Active_or_passive__accuracy: 1.0000 - Interaction_in_patenting_process_Active_or_passive__loss: 0.0019 - Nature_of_motivation_accuracy: 1.0000 - Nature_of_motivation_loss: 0.0030 - Relationship_between_standards_personal_values_accuracy: 1.0000 - Relationship_between_standards_personal_values_loss: 0.0018 - loss: 0.0098 - val_Classification_regarding_professional_orientation_accuracy: 0.6667 - val_Classification_regarding_professional_orientation_loss: 1.6026 - val_Interaction_in_patenting_process_Active_or_passive__accuracy: 0.3810 - val_Interaction_in_patenting_process_Active_or_passive__loss: 5.3146 - val_Nature_of_motivation_accuracy: 0.2381 - val_Nature_of_motivation_loss: 4.4639 - val_Relationship_between_standards_personal_values_accuracy: 0.2857 - val_Relationship_between_standards_personal_values_loss: 5.5026 - val_loss: 15.7590\n",
      "Epoch 50/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - Classification_regarding_professional_orientation_accuracy: 1.0000 - Classification_regarding_professional_orientation_loss: 0.0034 - Interaction_in_patenting_process_Active_or_passive__accuracy: 1.0000 - Interaction_in_patenting_process_Active_or_passive__loss: 0.0023 - Nature_of_motivation_accuracy: 1.0000 - Nature_of_motivation_loss: 0.0033 - Relationship_between_standards_personal_values_accuracy: 1.0000 - Relationship_between_standards_personal_values_loss: 0.0016 - loss: 0.0101 - val_Classification_regarding_professional_orientation_accuracy: 0.6190 - val_Classification_regarding_professional_orientation_loss: 1.5960 - val_Interaction_in_patenting_process_Active_or_passive__accuracy: 0.3810 - val_Interaction_in_patenting_process_Active_or_passive__loss: 5.3480 - val_Nature_of_motivation_accuracy: 0.2381 - val_Nature_of_motivation_loss: 4.5022 - val_Relationship_between_standards_personal_values_accuracy: 0.2857 - val_Relationship_between_standards_personal_values_loss: 5.5214 - val_loss: 15.8550\n",
      "\n",
      "=== Acurácias por coluna ===\n",
      "Interaction in patenting process. Active or passive?: 59.26%\n",
      "Classification regarding professional orientation: 48.15%\n",
      "Nature of motivation: 37.04%\n",
      "Relationship between standards / personal values: 59.26%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# === Carregar dados ===\n",
    "file_path = './dados_funcionais_patenteadores.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# === Targets ===\n",
    "target_columns = [\n",
    "    \"Interaction in patenting process. Active or passive?\",\n",
    "    \"Classification regarding professional orientation\",\n",
    "    \"Nature of motivation\",\n",
    "    \"Relationship between standards / personal values\"\n",
    "]\n",
    "\n",
    "# === Saneamento dos nomes para Keras ===\n",
    "def sanitize_name(name):\n",
    "    return re.sub(r'\\W+', '_', name)\n",
    "\n",
    "output_names = {col: sanitize_name(col) for col in target_columns}\n",
    "\n",
    "# === Separar X e y ===\n",
    "X = df.drop(columns=target_columns)\n",
    "y = df[target_columns]\n",
    "\n",
    "# === Pré-processamento dos dados de entrada ===\n",
    "numeric_features = X.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), numeric_features),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "])\n",
    "\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "X_array = X_processed.toarray() if hasattr(X_processed, \"toarray\") else X_processed\n",
    "X_reshaped = X_array.reshape((X_array.shape[0], X_array.shape[1], 1))\n",
    "\n",
    "# === Pré-processamento das saídas ===\n",
    "y_encoders = {}\n",
    "y_outputs = {}\n",
    "\n",
    "for col in target_columns:\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y[col])\n",
    "    y_categorical = to_categorical(y_encoded)\n",
    "    y_encoders[col] = le\n",
    "    y_outputs[col] = y_categorical\n",
    "\n",
    "# === Dividir treino/teste ===\n",
    "indices = np.arange(X_reshaped.shape[0])\n",
    "X_train, X_test, idx_train, idx_test = train_test_split(X_reshaped, indices, test_size=0.2, random_state=42)\n",
    "\n",
    "y_train = {output_names[col]: y_outputs[col][idx_train] for col in target_columns}\n",
    "y_test = {output_names[col]: y_outputs[col][idx_test] for col in target_columns}\n",
    "\n",
    "# === Modelo CNN Multi-saída ===\n",
    "input_layer = Input(shape=(X_reshaped.shape[1], 1))\n",
    "\n",
    "x = Conv1D(64, kernel_size=3, activation='relu')(input_layer)\n",
    "x = MaxPooling1D(pool_size=2)(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Conv1D(32, kernel_size=3, activation='relu')(x)\n",
    "x = MaxPooling1D(pool_size=2)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "\n",
    "# Saídas para cada coluna alvo\n",
    "outputs = {\n",
    "    output_names[col]: Dense(y_outputs[col].shape[1], activation='softmax', name=output_names[col])(x)\n",
    "    for col in target_columns\n",
    "}\n",
    "\n",
    "# Compilação do modelo\n",
    "model = Model(inputs=input_layer, outputs=outputs)\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss={name: 'categorical_crossentropy' for name in output_names.values()},\n",
    "    metrics={name: 'accuracy' for name in output_names.values()}\n",
    ")\n",
    "\n",
    "# === Treinar ===\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.2, verbose=1)\n",
    "\n",
    "# === Avaliar ===\n",
    "results = model.evaluate(X_test, y_test, verbose=0)\n",
    "metrics_names = model.metrics_names\n",
    "\n",
    "print(\"\\n=== Acurácias por coluna ===\")\n",
    "for col in target_columns:\n",
    "    y_true = np.argmax(y_test[output_names[col]], axis=1)\n",
    "    y_pred_prob = model.predict(X_test, verbose=0)[output_names[col]]\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    print(f\"{col}: {acc:.2%}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
