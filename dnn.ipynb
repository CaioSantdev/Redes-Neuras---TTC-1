{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b18301f8-3dd7-4336-9938-f8b024a198ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.6296296296296297\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Carregar os dados (substitua 'SuaÚltimaColuna' pelo nome real da última coluna)\n",
    "file_path = './dados_funcionais_patenteadores.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Selecione a coluna alvo e as variáveis de entrada\n",
    "target_column = 'Classification regarding professional orientation'  # Altere para o nome da última coluna\n",
    "X = df.drop(columns=[target_column])\n",
    "y = df[target_column]\n",
    "\n",
    "# Pré-processamento: normalização de variáveis numéricas e codificação de variáveis categóricas\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), X.select_dtypes(include=['float64', 'int64']).columns),  # Normaliza dados numéricos\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), X.select_dtypes(include=['object']).columns)  # Codifica dados categóricos\n",
    "    ])\n",
    "\n",
    "# Divisão dos dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Criar o pipeline que aplica o pré-processamento e o modelo MLP\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('mlp', MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "# Treinar o modelo\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Avaliar a acurácia do modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Acurácia: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff47bda2-0312-4441-b621-c20f78fb3976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.5555555555555556\n",
      "Acurácia média com validação cruzada: 0.5496828752642706\n",
      "\n",
      "Resultados das Previsões (Classes Reais vs Previsões):\n",
      "                      Real         Previsto\n",
      "55   Pragmatic traditional  Entrepreneurial\n",
      "40   Pragmatic traditional  Entrepreneurial\n",
      "19         Entrepreneurial           Hybrid\n",
      "31   Pragmatic traditional           Hybrid\n",
      "115                 Hybrid           Hybrid\n",
      "56                  Hybrid           Hybrid\n",
      "69                  Hybrid  Entrepreneurial\n",
      "105        Entrepreneurial  Entrepreneurial\n",
      "81         Entrepreneurial  Entrepreneurial\n",
      "26         Entrepreneurial           Hybrid\n",
      "\n",
      "Número de acertos por classe:\n",
      "Real\n",
      "Entrepreneurial     5\n",
      "Hybrid             10\n",
      "dtype: int64\n",
      "\n",
      "Previsões Erradas (Real vs Previsto):\n",
      "                      Real               Previsto\n",
      "55   Pragmatic traditional        Entrepreneurial\n",
      "40   Pragmatic traditional        Entrepreneurial\n",
      "19         Entrepreneurial                 Hybrid\n",
      "31   Pragmatic traditional                 Hybrid\n",
      "69                  Hybrid        Entrepreneurial\n",
      "26         Entrepreneurial                 Hybrid\n",
      "95         Entrepreneurial                 Hybrid\n",
      "27         Entrepreneurial                 Hybrid\n",
      "97   Pragmatic traditional                 Hybrid\n",
      "100                 Hybrid  Pragmatic traditional\n",
      "36                  Hybrid        Entrepreneurial\n",
      "18         Entrepreneurial                 Hybrid\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Carregar os dados\n",
    "file_path = './dados_funcionais_patenteadores.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Selecione a coluna alvo e as variáveis de entrada\n",
    "target_column = 'Classification regarding professional orientation'  # Altere para o nome da última coluna\n",
    "X = df.drop(columns=[target_column])\n",
    "y = df[target_column]\n",
    "\n",
    "# Pré-processamento: normalização de variáveis numéricas e codificação de variáveis categóricas\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), X.select_dtypes(include=['float64', 'int64']).columns),  # Normaliza dados numéricos\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), X.select_dtypes(include=['object']).columns)  # Codifica dados categóricos\n",
    "    ])\n",
    "\n",
    "# Divisão dos dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Criar o pipeline que aplica o pré-processamento e o modelo MLP\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('mlp', MLPClassifier(hidden_layer_sizes=(128, 64, 32), max_iter=2000, random_state=42, solver='adam', activation='relu'))\n",
    "])\n",
    "\n",
    "# Treinar o modelo\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Avaliar a acurácia do modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Acurácia: {accuracy}')\n",
    "\n",
    "\n",
    "# Validar o modelo com cross-validation\n",
    "cv_scores = cross_val_score(pipeline, X, y, cv=3, scoring='accuracy')\n",
    "print(f\"Acurácia média com validação cruzada: {cv_scores.mean()}\")\n",
    "\n",
    "# --- Exibir os resultados das previsões e perfis reais ---\n",
    "# Criando uma tabela com as classes reais e previstas\n",
    "results_df = pd.DataFrame({\n",
    "    'Real': y_test,\n",
    "    'Previsto': y_pred\n",
    "})\n",
    "\n",
    "# Exibir as primeiras 10 linhas\n",
    "print(\"\\nResultados das Previsões (Classes Reais vs Previsões):\")\n",
    "print(results_df.head(10))  # Exibe as 10 primeiras linhas para ver o resultado\n",
    "\n",
    "# Exibir o número total de acertos para cada classe\n",
    "print(\"\\nNúmero de acertos por classe:\")\n",
    "print(results_df[results_df['Real'] == results_df['Previsto']].groupby('Real').size())\n",
    "\n",
    "# Exibir as previsões erradas\n",
    "print(\"\\nPrevisões Erradas (Real vs Previsto):\")\n",
    "print(results_df[results_df['Real'] != results_df['Previsto']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c27a435-90b9-4ccb-b89d-19170152ed66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bc682d-a214-45c5-9a7d-a96fef9804cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170c3dbe-2caa-4ee4-aafa-f5035214155a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2489530e-da1a-4027-bd8c-d1775a7ace0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.2673 - val_loss: 0.2585\n",
      "Epoch 2/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2630 - val_loss: 0.2505\n",
      "Epoch 3/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.2532 - val_loss: 0.2306\n",
      "Epoch 4/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2294 - val_loss: 0.1865\n",
      "Epoch 5/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1792 - val_loss: 0.1141\n",
      "Epoch 6/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.1063 - val_loss: 0.0583\n",
      "Epoch 7/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0613 - val_loss: 0.0472\n",
      "Epoch 8/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0537 - val_loss: 0.0465\n",
      "Epoch 9/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0529 - val_loss: 0.0459\n",
      "Epoch 10/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0522 - val_loss: 0.0445\n",
      "Epoch 11/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0514 - val_loss: 0.0438\n",
      "Epoch 12/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0511 - val_loss: 0.0438\n",
      "Epoch 13/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0509 - val_loss: 0.0437\n",
      "Epoch 14/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0508 - val_loss: 0.0433\n",
      "Epoch 15/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0505 - val_loss: 0.0432\n",
      "Epoch 16/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0504 - val_loss: 0.0432\n",
      "Epoch 17/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0503 - val_loss: 0.0432\n",
      "Epoch 18/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0502 - val_loss: 0.0430\n",
      "Epoch 19/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0500 - val_loss: 0.0428\n",
      "Epoch 20/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0498 - val_loss: 0.0427\n",
      "Epoch 21/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0496 - val_loss: 0.0426\n",
      "Epoch 22/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0493 - val_loss: 0.0424\n",
      "Epoch 23/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0490 - val_loss: 0.0421\n",
      "Epoch 24/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0486 - val_loss: 0.0418\n",
      "Epoch 25/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0482 - val_loss: 0.0415\n",
      "Epoch 26/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0478 - val_loss: 0.0412\n",
      "Epoch 27/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0474 - val_loss: 0.0408\n",
      "Epoch 28/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0470 - val_loss: 0.0406\n",
      "Epoch 29/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0467 - val_loss: 0.0404\n",
      "Epoch 30/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0464 - val_loss: 0.0402\n",
      "Epoch 31/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0461 - val_loss: 0.0400\n",
      "Epoch 32/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0459 - val_loss: 0.0399\n",
      "Epoch 33/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0456 - val_loss: 0.0397\n",
      "Epoch 34/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0453 - val_loss: 0.0395\n",
      "Epoch 35/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0450 - val_loss: 0.0393\n",
      "Epoch 36/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0447 - val_loss: 0.0391\n",
      "Epoch 37/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0444 - val_loss: 0.0389\n",
      "Epoch 38/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0442 - val_loss: 0.0387\n",
      "Epoch 39/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0439 - val_loss: 0.0385\n",
      "Epoch 40/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0437 - val_loss: 0.0384\n",
      "Epoch 41/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0434 - val_loss: 0.0382\n",
      "Epoch 42/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0432 - val_loss: 0.0380\n",
      "Epoch 43/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0430 - val_loss: 0.0378\n",
      "Epoch 44/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0428 - val_loss: 0.0376\n",
      "Epoch 45/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0427 - val_loss: 0.0375\n",
      "Epoch 46/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0425 - val_loss: 0.0374\n",
      "Epoch 47/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0423 - val_loss: 0.0373\n",
      "Epoch 48/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0422 - val_loss: 0.0372\n",
      "Epoch 49/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0421 - val_loss: 0.0371\n",
      "Epoch 50/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0419 - val_loss: 0.0370\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/caio/.pyenv/versions/3.11.0/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.3141 - loss: 1.2979 - val_accuracy: 0.2222 - val_loss: 1.1622\n",
      "Epoch 2/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4063 - loss: 1.0965 - val_accuracy: 0.2963 - val_loss: 1.1552\n",
      "Epoch 3/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4391 - loss: 1.0413 - val_accuracy: 0.3704 - val_loss: 1.0977\n",
      "Epoch 4/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4635 - loss: 1.0238 - val_accuracy: 0.4815 - val_loss: 1.0718\n",
      "Epoch 5/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5115 - loss: 1.0182 - val_accuracy: 0.5926 - val_loss: 1.0630\n",
      "Epoch 6/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5352 - loss: 0.9860 - val_accuracy: 0.5556 - val_loss: 1.0541\n",
      "Epoch 7/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5352 - loss: 0.9664 - val_accuracy: 0.5556 - val_loss: 1.0299\n",
      "Epoch 8/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5470 - loss: 0.9548 - val_accuracy: 0.5556 - val_loss: 1.0220\n",
      "Epoch 9/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5840 - loss: 0.9475 - val_accuracy: 0.5556 - val_loss: 1.0116\n",
      "Epoch 10/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5871 - loss: 0.9380 - val_accuracy: 0.4815 - val_loss: 1.0114\n",
      "Epoch 11/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5909 - loss: 0.9281 - val_accuracy: 0.4815 - val_loss: 1.0127\n",
      "Epoch 12/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5878 - loss: 0.9239 - val_accuracy: 0.4815 - val_loss: 1.0020\n",
      "Epoch 13/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6184 - loss: 0.9221 - val_accuracy: 0.4815 - val_loss: 0.9950\n",
      "Epoch 14/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6212 - loss: 0.9096 - val_accuracy: 0.5185 - val_loss: 0.9929\n",
      "Epoch 15/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6275 - loss: 0.8994 - val_accuracy: 0.4815 - val_loss: 0.9894\n",
      "Epoch 16/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6122 - loss: 0.9017 - val_accuracy: 0.5556 - val_loss: 0.9900\n",
      "Epoch 17/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6365 - loss: 0.8873 - val_accuracy: 0.4815 - val_loss: 0.9722\n",
      "Epoch 18/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6637 - loss: 0.8823 - val_accuracy: 0.4815 - val_loss: 0.9733\n",
      "Epoch 19/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6637 - loss: 0.8723 - val_accuracy: 0.4815 - val_loss: 0.9735\n",
      "Epoch 20/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6700 - loss: 0.8661 - val_accuracy: 0.5556 - val_loss: 0.9753\n",
      "Epoch 21/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6640 - loss: 0.8539 - val_accuracy: 0.4815 - val_loss: 0.9737\n",
      "Epoch 22/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6578 - loss: 0.8471 - val_accuracy: 0.4815 - val_loss: 0.9655\n",
      "Epoch 23/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6700 - loss: 0.8429 - val_accuracy: 0.5185 - val_loss: 0.9779\n",
      "Epoch 24/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6609 - loss: 0.8286 - val_accuracy: 0.4815 - val_loss: 0.9705\n",
      "Epoch 25/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6700 - loss: 0.8262 - val_accuracy: 0.5185 - val_loss: 0.9688\n",
      "Epoch 26/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6609 - loss: 0.8154 - val_accuracy: 0.5185 - val_loss: 0.9653\n",
      "Epoch 27/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6700 - loss: 0.8074 - val_accuracy: 0.5185 - val_loss: 0.9676\n",
      "Epoch 28/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6700 - loss: 0.8012 - val_accuracy: 0.5185 - val_loss: 0.9680\n",
      "Epoch 29/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6700 - loss: 0.7929 - val_accuracy: 0.5185 - val_loss: 0.9676\n",
      "Epoch 30/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6762 - loss: 0.7832 - val_accuracy: 0.5185 - val_loss: 0.9669\n",
      "Epoch 31/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6793 - loss: 0.7747 - val_accuracy: 0.5185 - val_loss: 0.9591\n",
      "Epoch 32/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6974 - loss: 0.7678 - val_accuracy: 0.5185 - val_loss: 0.9625\n",
      "Epoch 33/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7065 - loss: 0.7590 - val_accuracy: 0.5185 - val_loss: 0.9663\n",
      "Epoch 34/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7034 - loss: 0.7524 - val_accuracy: 0.5185 - val_loss: 0.9752\n",
      "Epoch 35/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7124 - loss: 0.7421 - val_accuracy: 0.4815 - val_loss: 0.9641\n",
      "Epoch 36/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6974 - loss: 0.7366 - val_accuracy: 0.4815 - val_loss: 0.9676\n",
      "Epoch 37/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7124 - loss: 0.7271 - val_accuracy: 0.4815 - val_loss: 0.9730\n",
      "Epoch 38/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7183 - loss: 0.7203 - val_accuracy: 0.4815 - val_loss: 0.9751\n",
      "Epoch 39/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7430 - loss: 0.7103 - val_accuracy: 0.5185 - val_loss: 0.9711\n",
      "Epoch 40/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7490 - loss: 0.7034 - val_accuracy: 0.5185 - val_loss: 0.9792\n",
      "Epoch 41/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7490 - loss: 0.6934 - val_accuracy: 0.5185 - val_loss: 0.9777\n",
      "Epoch 42/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7490 - loss: 0.6861 - val_accuracy: 0.5185 - val_loss: 0.9756\n",
      "Epoch 43/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7490 - loss: 0.6790 - val_accuracy: 0.5185 - val_loss: 0.9879\n",
      "Epoch 44/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7490 - loss: 0.6663 - val_accuracy: 0.5185 - val_loss: 0.9882\n",
      "Epoch 45/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7608 - loss: 0.6643 - val_accuracy: 0.5185 - val_loss: 0.9953\n",
      "Epoch 46/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7549 - loss: 0.6525 - val_accuracy: 0.5185 - val_loss: 0.9976\n",
      "Epoch 47/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7608 - loss: 0.6437 - val_accuracy: 0.5185 - val_loss: 0.9912\n",
      "Epoch 48/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7608 - loss: 0.6375 - val_accuracy: 0.5185 - val_loss: 1.0040\n",
      "Epoch 49/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7789 - loss: 0.6272 - val_accuracy: 0.5185 - val_loss: 1.0014\n",
      "Epoch 50/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7608 - loss: 0.6212 - val_accuracy: 0.5185 - val_loss: 1.0135\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Acurácia do modelo com Autoencoder + MLP: 0.5185185185185185\n",
      "\n",
      "Resultados das Previsões (Classes Reais vs Previsões):\n",
      "        Real   Previsto\n",
      "0  Intrinsic  Intrinsic\n",
      "1      Mixed      Mixed\n",
      "2  Extrinsic  Intrinsic\n",
      "3      Mixed  Extrinsic\n",
      "4  Intrinsic      Mixed\n",
      "5  Extrinsic  Intrinsic\n",
      "6      Mixed      Mixed\n",
      "7  Extrinsic  Intrinsic\n",
      "8  Intrinsic  Extrinsic\n",
      "9  Extrinsic  Intrinsic\n",
      "\n",
      "Número de acertos por classe:\n",
      "Real\n",
      "Extrinsic    5\n",
      "Intrinsic    4\n",
      "Mixed        5\n",
      "dtype: int64\n",
      "\n",
      "Previsões Erradas (Real vs Previsto):\n",
      "         Real   Previsto\n",
      "2   Extrinsic  Intrinsic\n",
      "3       Mixed  Extrinsic\n",
      "4   Intrinsic      Mixed\n",
      "5   Extrinsic  Intrinsic\n",
      "7   Extrinsic  Intrinsic\n",
      "8   Intrinsic  Extrinsic\n",
      "9   Extrinsic  Intrinsic\n",
      "12      Mixed  Intrinsic\n",
      "13  Intrinsic  Extrinsic\n",
      "14  Intrinsic      Mixed\n",
      "16  Intrinsic  Extrinsic\n",
      "21      Mixed  Intrinsic\n",
      "26  Intrinsic  Extrinsic\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Definir a semente para garantir reprodutibilidade\n",
    "seed_value = 42\n",
    "\n",
    "# Definir semente do Python\n",
    "random.seed(seed_value)\n",
    "\n",
    "# Definir semente do NumPy\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# Definir semente do TensorFlow\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "# Importações do código original\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Carregar os dados\n",
    "df = pd.read_excel('./dados_funcionais_patenteadores.xlsx')\n",
    "\n",
    "# Selecione a coluna alvo e as variáveis de entrada\n",
    "X = df.drop(columns=['Nature of motivation'])\n",
    "y = df['Nature of motivation']\n",
    "\n",
    "# Selecionar apenas as colunas numéricas para normalização\n",
    "X_numeric = X.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Normalização dos dados numéricos\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_numeric)\n",
    "\n",
    "# Selecionar as colunas categóricas para codificação\n",
    "X_categorical = X.select_dtypes(include=['object'])\n",
    "\n",
    "# Codificação das variáveis categóricas com OneHotEncoder\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)  # Corrigido para 'sparse_output=False'\n",
    "X_encoded = encoder.fit_transform(X_categorical)\n",
    "\n",
    "# Concatenar as variáveis numéricas normalizadas com as variáveis categóricas codificadas\n",
    "X_final = np.concatenate((X_scaled, X_encoded), axis=1)\n",
    "\n",
    "# Convertendo as variáveis alvo (y_train e y_test) para inteiros\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Dividir os dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- Construção do Autoencoder ---\n",
    "input_dim = X_train.shape[1]  # Número total de características de entrada\n",
    "encoding_dim = 64  # Dimensão da camada comprimida (representação compacta)\n",
    "\n",
    "# Definir o Autoencoder\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoded = Dense(128, activation='relu')(input_layer)\n",
    "encoded = Dense(64, activation='relu')(encoded)\n",
    "encoded = Dense(encoding_dim, activation='relu')(encoded)\n",
    "\n",
    "decoded = Dense(64, activation='relu')(encoded)\n",
    "decoded = Dense(128, activation='relu')(decoded)\n",
    "decoded = Dense(input_dim, activation='sigmoid')(decoded)\n",
    "\n",
    "# Modelo Autoencoder\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "\n",
    "# Modelo Encoder (para obter a codificação comprimida)\n",
    "encoder_model = Model(input_layer, encoded)\n",
    "\n",
    "# Compilação do Autoencoder\n",
    "autoencoder.compile(optimizer=Adam(), loss='mean_squared_error')\n",
    "\n",
    "# Treinar o Autoencoder\n",
    "autoencoder.fit(X_train, X_train, epochs=50, batch_size=32, validation_data=(X_test, X_test))\n",
    "\n",
    "# --- Obter as Representações Comprimidas com o Encoder ---\n",
    "X_train_encoded = encoder_model.predict(X_train)\n",
    "X_test_encoded = encoder_model.predict(X_test)\n",
    "\n",
    "# --- Construção do MLP ---\n",
    "# O MLP agora vai usar as representações comprimidas como entrada\n",
    "mlp_model = Sequential([\n",
    "    Dense(128, activation='relu', input_dim=encoding_dim),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(len(np.unique(y_encoded)), activation='softmax')  # Para classificação multi-classe\n",
    "])\n",
    "\n",
    "# Compilar o modelo MLP\n",
    "mlp_model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Treinar o MLP\n",
    "mlp_model.fit(X_train_encoded, y_train, epochs=50, batch_size=32, validation_data=(X_test_encoded, y_test))\n",
    "\n",
    "# Avaliar a acurácia do MLP\n",
    "y_pred = mlp_model.predict(X_test_encoded)\n",
    "y_pred_classes = y_pred.argmax(axis=-1)  # Converter as probabilidades para classes\n",
    "\n",
    "# Calcular a acurácia\n",
    "accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "print(f'Acurácia do modelo com Autoencoder + MLP: {accuracy}')\n",
    "\n",
    "\n",
    "# --- Exibir os resultados das previsões ---\n",
    "# Criando uma tabela com as classes reais e previstas\n",
    "results_df = pd.DataFrame({\n",
    "    'Real': label_encoder.inverse_transform(y_test),\n",
    "    'Previsto': label_encoder.inverse_transform(y_pred_classes)\n",
    "})\n",
    "\n",
    "print(\"\\nResultados das Previsões (Classes Reais vs Previsões):\")\n",
    "print(results_df.head(10))  # Exibe as 10 primeiras linhas para ver o resultado\n",
    "\n",
    "# Exibir o número total de acertos para cada classe\n",
    "print(\"\\nNúmero de acertos por classe:\")\n",
    "print(results_df[results_df['Real'] == results_df['Previsto']].groupby('Real').size())\n",
    "\n",
    "# Exibir as previsões erradas\n",
    "print(\"\\nPrevisões Erradas (Real vs Previsto):\")\n",
    "print(results_df[results_df['Real'] != results_df['Previsto']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e20ca24-ed40-455f-aaac-2791ae7a240e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38b886b-bf65-47ab-a145-c29982ac6bf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
